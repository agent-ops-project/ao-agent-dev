{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Debug Notebook\n",
    "This notebook helps inspect the PostgreSQL database to debug the foreign key violation issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/ferdi/Documents/agent-copilot/src')\n",
    "\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "from urllib.parse import urlparse\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Import the database module\n",
    "from aco.server import db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the database URL from environment or config\n",
    "from aco.common.constants import DATABASE_URL\n",
    "\n",
    "if DATABASE_URL:\n",
    "    print(f\"Database URL found: {DATABASE_URL.split('@')[1] if '@' in DATABASE_URL else DATABASE_URL}\")\n",
    "    conn = db.get_conn()\n",
    "    print(\"Connected to database successfully\")\n",
    "else:\n",
    "    print(\"No DATABASE_URL found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List All Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all experiments\n",
    "experiments = db.query_all(\n",
    "    \"SELECT session_id, parent_session_id, name, timestamp, success, notes FROM experiments ORDER BY timestamp DESC LIMIT 20\"\n",
    ")\n",
    "\n",
    "if experiments:\n",
    "    df_experiments = pd.DataFrame(experiments)\n",
    "    print(f\"Found {len(experiments)} experiments:\")\n",
    "    display(df_experiments)\n",
    "else:\n",
    "    print(\"No experiments found in database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Specific Session ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the problematic session_id from the error\n",
    "problematic_session_id = \"4c1ab5d2-5e84-402b-bd87-8f02250fe2fc\"\n",
    "\n",
    "exists = db.query_one(\n",
    "    \"SELECT * FROM experiments WHERE session_id = ?\",\n",
    "    (problematic_session_id,)\n",
    ")\n",
    "\n",
    "if exists:\n",
    "    print(f\"Session {problematic_session_id} EXISTS in experiments table:\")\n",
    "    for key, value in dict(exists).items():\n",
    "        if key not in ['graph_topology', 'environment', 'log']:\n",
    "            print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(f\"Session {problematic_session_id} DOES NOT EXIST in experiments table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check LLM Calls Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get recent LLM calls\n",
    "llm_calls = db.query_all(\n",
    "    \"SELECT session_id, node_id, api_type, timestamp FROM llm_calls ORDER BY timestamp DESC LIMIT 20\"\n",
    ")\n",
    "\n",
    "if llm_calls:\n",
    "    df_llm = pd.DataFrame(llm_calls)\n",
    "    print(f\"Found {len(llm_calls)} recent LLM calls:\")\n",
    "    display(df_llm)\n",
    "else:\n",
    "    print(\"No LLM calls found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Orphaned LLM Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find LLM calls with session_ids that don't exist in experiments\n",
    "orphaned = db.query_all(\n",
    "    \"\"\"\n",
    "    SELECT DISTINCT l.session_id, COUNT(*) as call_count\n",
    "    FROM llm_calls l\n",
    "    LEFT JOIN experiments e ON l.session_id = e.session_id\n",
    "    WHERE e.session_id IS NULL\n",
    "    GROUP BY l.session_id\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "if orphaned:\n",
    "    print(f\"Found {len(orphaned)} session(s) with orphaned LLM calls:\")\n",
    "    for row in orphaned:\n",
    "        print(f\"  Session {row['session_id']}: {row['call_count']} orphaned calls\")\n",
    "else:\n",
    "    print(\"No orphaned LLM calls found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Foreign Key Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check foreign key constraints in the database\n",
    "constraints = db.query_all(\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "        tc.table_name, \n",
    "        kcu.column_name, \n",
    "        ccu.table_name AS foreign_table_name,\n",
    "        ccu.column_name AS foreign_column_name \n",
    "    FROM \n",
    "        information_schema.table_constraints AS tc \n",
    "        JOIN information_schema.key_column_usage AS kcu\n",
    "          ON tc.constraint_name = kcu.constraint_name\n",
    "          AND tc.table_schema = kcu.table_schema\n",
    "        JOIN information_schema.constraint_column_usage AS ccu\n",
    "          ON ccu.constraint_name = tc.constraint_name\n",
    "          AND ccu.table_schema = tc.table_schema\n",
    "    WHERE tc.constraint_type = 'FOREIGN KEY'\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "if constraints:\n",
    "    print(\"Foreign key constraints:\")\n",
    "    for c in constraints:\n",
    "        print(f\"  {c['table_name']}.{c['column_name']} -> {c['foreign_table_name']}.{c['foreign_column_name']}\")\n",
    "else:\n",
    "    print(\"No foreign key constraints found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up Orphaned Records (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete orphaned LLM calls\n",
    "# WARNING: This will delete data!\n",
    "\n",
    "# orphaned_sessions = db.query_all(\n",
    "#     \"\"\"\n",
    "#     SELECT DISTINCT l.session_id\n",
    "#     FROM llm_calls l\n",
    "#     LEFT JOIN experiments e ON l.session_id = e.session_id\n",
    "#     WHERE e.session_id IS NULL\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "# if orphaned_sessions:\n",
    "#     for row in orphaned_sessions:\n",
    "#         session_id = row['session_id']\n",
    "#         print(f\"Deleting orphaned LLM calls for session {session_id}\")\n",
    "#         db.execute(\"DELETE FROM llm_calls WHERE session_id = ?\", (session_id,))\n",
    "#     print(f\"Deleted orphaned calls for {len(orphaned_sessions)} sessions\")\n",
    "# else:\n",
    "#     print(\"No orphaned records to clean up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert Missing Experiment (Emergency Fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a placeholder experiment for the problematic session if it doesn't exist\n",
    "# Uncomment and modify session_id to use\n",
    "\n",
    "# import json\n",
    "# from datetime import datetime\n",
    "\n",
    "# session_to_fix = \"4c1ab5d2-5e84-402b-bd87-8f02250fe2fc\"\n",
    "\n",
    "# exists = db.query_one(\n",
    "#     \"SELECT session_id FROM experiments WHERE session_id = ?\",\n",
    "#     (session_to_fix,)\n",
    "# )\n",
    "\n",
    "# if not exists:\n",
    "#     print(f\"Creating placeholder experiment for session {session_to_fix}\")\n",
    "#     db.execute(\n",
    "#         \"INSERT INTO experiments (session_id, parent_session_id, name, graph_topology, timestamp, cwd, command, environment, success, notes, log) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\",\n",
    "#         (\n",
    "#             session_to_fix,\n",
    "#             session_to_fix,\n",
    "#             \"Recovered session\",\n",
    "#             json.dumps({\"nodes\": [], \"edges\": []}),\n",
    "#             datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "#             \"unknown\",\n",
    "#             \"unknown\",\n",
    "#             json.dumps({}),\n",
    "#             \"\",\n",
    "#             \"Auto-created to fix foreign key violation\",\n",
    "#             \"\",\n",
    "#         ),\n",
    "#     )\n",
    "#     print(\"Experiment created successfully\")\n",
    "# else:\n",
    "#     print(f\"Session {session_to_fix} already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor Real-time Insertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the most recent experiments and LLM calls\n",
    "import time\n",
    "\n",
    "print(\"Most recent activity:\")\n",
    "print(\"\\nLast 5 experiments:\")\n",
    "recent_exp = db.query_all(\n",
    "    \"SELECT session_id, name, timestamp FROM experiments ORDER BY timestamp DESC LIMIT 5\"\n",
    ")\n",
    "for exp in recent_exp:\n",
    "    print(f\"  {exp['timestamp']}: {exp['session_id'][:8]}... - {exp['name']}\")\n",
    "\n",
    "print(\"\\nLast 5 LLM calls:\")\n",
    "recent_llm = db.query_all(\n",
    "    \"SELECT session_id, node_id, timestamp FROM llm_calls ORDER BY timestamp DESC LIMIT 5\"\n",
    ")\n",
    "for llm in recent_llm:\n",
    "    print(f\"  {llm['timestamp']}: {llm['session_id'][:8]}... - Node: {llm['node_id'][:8]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}