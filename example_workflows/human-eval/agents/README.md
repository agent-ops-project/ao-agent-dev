# Human-eval

## Quick start with basic agent
1. Run `aco-launch agents/basic.py` to generate completions.
2. Run `evaluate_functional_correctness outputs/basic_samples.jsonl` to evaluate the completions.