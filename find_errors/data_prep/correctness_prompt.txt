
I have a high-level design doc and want to turn it into code using LLMs. I chain together several LLM calls to achieve this, were I first have a planning phase and then a transpilation phase.

Below are an outputs and review for one of the steps. Based on the output and the review, I want you to label the step's correctness as either 'certainly correct', 'uncertain', or 'certainly wrong'.

Your rating must only contain one of these three values. This is how you should assign them:

1. 'certainly correct': Based on code and review, the step produced an output that is certainly correct and will not cause any problems further down the transpilation process.

2. 'uncertain': It is hard to tell whether the output is correct or incorrect.

3. 'certainly incorrect': Based on code and review, the step produced an output that is certainly incorrect as is. The problems might be fixable in the future but the current output is erreneous, either by being too vague, underspecified or producing wrong code (e.g., code that doesn't compile).

Here is the LLM's output:
---------------------------------------------
class DBOperationsInterface:
    """
    Interface for defining all database related operations to backup the CRM.
    """
    def __init__(self,
                 db_name: str,
                 schema: Schema,
                 host: str,
                 port: str,
                 user: str,
                 password: str,
                 max_retry: int = 3,
                 timeout_s: int = 200):
        """
        Feel free to add any other attributes you think may be useful
        """
        self.db_name = db_name
        self.schema = schema
        self.host = host
        self.port = port
        self.user = user
        self.password = password
        self.max_retry = max_retry
        self.timeout_s = timeout_s
        self.conn = None

    def get_connection(self) -> bool:
        """
        Using psycopg package to create a database connection to database named self.db_name.
        """
        pass

    def close_connection(self) -> bool:
        """
        close the psycopg connection in self.conn and set it to None
        """
        pass

    def create_database_schema(self) -> bool:
        """
        Execute SQL query to load the database schema.
        """
        pass

    def execute_query(self, query: str):
        """
        Execute the SQL query provided and return the results.
        """
        pass

    def create_table(self, table_name: str) -> bool:
        """
        Execute this SQL query to create table. Do not do anything if the table exists.
        """
        pass

    def drop_table(self, table_name: str) -> bool:
        """
        Execute this SQL query to drop an existing table.
        """
        pass

    def insert_record(self, table_name: str, record: t.List[t.Any]) -> bool:
        """
        Insert one record into table.
        """
        pass

    def update_record(self, table_name: str, record: t.List[t.Any]) -> bool:
        """
        Update one record in the table.
        """
        pass

    def delete_record(self, table_name: str, record_id: int) -> bool:
        """
        Delete record with record_id in the table.
        """
        pass

    def load_from_csv(self, table_name: str, csv_path: str, sep: str = '|', header: bool = False) -> bool:
        """
        Load a batch of records from csv.
        """
        pass

    def create_index(self, index_name: str, table_name: str, col_names: t.List[str]) -> bool:
        """
        Create an index with name index_name on table (table_name) over a list of columns (col_names).
        """
        pass

    def drop_index(self, index_name: str) -> bool:
        """
        Write and execute an SQL in Postgres syntax to drop an index.
        """
        pass


class PostgresOperations(DBOperationsInterface):
    """
    Interface for defining all database related operations to backup the CRM.
    """

    def __init__(self,
                 db_name: str,
                 schema: Schema,
                 host: str,
                 port: str,
                 user: str,
                 password: str,
                 max_retry: int = 3,
                 timeout_s: int = 200):
        """
        Feel free to add any other attributes you think may be useful
        """
        self.db_name = db_name
        self.schema = schema
        self.host = host
        self.port = port
        self.user = user
        self.password = password
        self.max_retry = max_retry
        self.timeout_s = timeout_s
        self.conn = None
        self.logger = logging.getLogger(__name__)

    def _execute_with_retry(self, query: str, params: t.Optional[t.List] = None, retry_count: int = 0) -> t.Optional[t.List]:
        """
        Helper method to execute a query with retry logic.
        
        Args:
            query: SQL query to execute
            params: Parameters for the query
            retry_count: Current retry count
            
        Returns:
            Query results or None if execution failed
        """
        if retry_count >= self.max_retry:
            self.logger.error(f"Max retry count reached for query: {query}")
            return None
            
        if self.conn is None:
            if not self.get_connection():
                self.logger.error("Failed to get connection")
                return None
                
        try:
            with self.conn.cursor() as cursor:
                cursor.execute(query, params)
                try:
                    results = cursor.fetchall()
                    return results
                except psycopg.ProgrammingError:
                    # No results to fetch (e.g., for INSERT, UPDATE, DELETE)
                    return []
        except Exception as e:
            self.logger.error(f"Error executing query: {e}")
            time.sleep(1)  # Sleep for 1 second before retrying
            return self._execute_with_retry(query, params, retry_count + 1)
    
    def _table_exists(self, table_name: str) -> bool:
        """
        Check if a table exists in the database.
        
        Args:
            table_name: Name of the table to check
            
        Returns:
            True if table exists, False otherwise
        """
        query = """
        SELECT EXISTS (
            SELECT FROM information_schema.tables 
            WHERE table_name = %s
        );
        """
        result = self._execute_with_retry(query, [table_name])
        if result and result[0][0]:
            return True
        return False
    
    def _record_exists(self, table_name: str, record_id: int) -> bool:
        """
        Check if a record exists in a table.
        
        Args:
            table_name: Name of the table
            record_id: ID of the record to check
            
        Returns:
            True if record exists, False otherwise
        """
        if not self._table_exists(table_name):
            return False
            
        primary_key = self.schema.table_dictionary[table_name].primary_key[0]
        query = f"SELECT EXISTS (SELECT 1 FROM {table_name} WHERE {primary_key} = %s);"
        result = self._execute_with_retry(query, [record_id])
        if result and result[0][0]:
            return True
        return False

    def get_connection(self) -> bool:
        """
        Using psycopg package to create a database connection to database named self.db_name.
        If self.db_name does not exist, you should first connect to admin database with name 'postgres',
        create a database with name self.db_name, and then connect to self.db_name.
        Set it as self.conn
        Hint: You can set conn.autocommit = True to avoid commit transaction every time
         after setting the connection, you should set the timeout in seconds as self._timeout_s,
        Returns:
            bool: True if successfully connected, False otherwise.
        """
        try:
            # Try connecting to the specified database
            conn_string = f"dbname={self.db_name} user={self.user} password={self.password} host={self.host} port={self.port}"
            self.conn = psycopg.connect(conn_string, connect_timeout=self.timeout_s)
            self.conn.autocommit = True
            return True
        except psycopg.Error as e:
            # If database doesn't exist, connect to postgres and create it
            if "database" in str(e) and "does not exist" in str(e):
                try:
                    # Connect to postgres admin database
                    admin_conn_string = f"dbname=postgres user={self.user} password={self.password} host={self.host} port={self.port}"
                    admin_conn = psycopg.connect(admin_conn_string, connect_timeout=self.timeout_s)
                    admin_conn.autocommit = True
                    
                    # Create the database
                    with admin_conn.cursor() as cursor:
                        cursor.execute(f"CREATE DATABASE {self.db_name};")
                    
                    # Close admin connection
                    admin_conn.close()
                    
                    # Connect to the newly created database
                    conn_string = f"dbname={self.db_name} user={self.user} password={self.password} host={self.host} port={self.port}"
                    self.conn = psycopg.connect(conn_string, connect_timeout=self.timeout_s)
                    self.conn.autocommit = True
                    return True
                except Exception as create_error:
                    self.logger.error(f"Failed to create database: {create_error}")
                    return False
            else:
                self.logger.error(f"Failed to connect to database: {e}")
                return False

    def close_connection(self) -> bool:
        """
        close the psycopg connection in self.conn and set it to None
        Returns:
            bool: True if successfully closed connection, False otherwise.
        """
        if self.conn is not None:
            try:
                self.conn.close()
                self.conn = None
                return True
            except Exception as e:
                self.logger.error(f"Failed to close connection: {e}")
                return False
        return True  # Connection was already closed

    def create_database_schema(self) -> bool:
        """
        Execute SQL query (self.schema.schema_sql_statement) to create the database schema.
        Returns:
            bool: True if successfully created schema, False otherwise.
        """
        if self.conn is None and not self.get_connection():
            return False
            
        try:
            # Execute the schema SQL statement
            with self.conn.cursor() as cursor:
                cursor.execute(self.schema.schema_sql_statement)
            return True
        except Exception as e:
            self.logger.error(f"Failed to create database schema: {e}")
            return False

    def drop_database(self) -> bool:
        """
        Drop self.db_name database,
        You should create a connection to admin database with name 'postgres', then write SQL in Postgres-syntax to
        drop this database.
        Close connection
        Returns:
            bool: True if successfully dropped, False otherwise.
        """
        # Close current connection if it exists
        if self.conn is not None:
            self.close_connection()
            
        try:
            # Connect to postgres admin database
            admin_conn_string = f"dbname=postgres user={self.user} password={self.password} host={self.host} port={self.port}"
            admin_conn = psycopg.connect(admin_conn_string, connect_timeout=self.timeout_s)
            admin_conn.autocommit = True
            
            # Drop the database
            with admin_conn.cursor() as cursor:
                # Terminate all connections to the database before dropping
                cursor.execute(f"""
                SELECT pg_terminate_backend(pg_stat_activity.pid)
                FROM pg_stat_activity
                WHERE pg_stat_activity.datname = '{self.db_name}'
                AND pid <> pg_backend_pid();
                """)
                cursor.execute(f"DROP DATABASE IF EXISTS {self.db_name};")
            
            # Close admin connection
            admin_conn.close()
            return True
        except Exception as e:
            self.logger.error(f"Failed to drop database: {e}")
            return False
---------------------------------------------

Here is the review to this output:
---------------------------------------------
# Performed Steps
In this first iteration, I've implemented:
1. All necessary imports
2. Helper methods for retry logic and table/record existence checking
3. Connection management methods (get_connection, close_connection, drop_database)
4. Schema creation method (create_database_schema)

## Full Completions
- Added all necessary imports
- Implemented helper methods:
  - _execute_with_retry: Handles retry logic for database operations
  - _table_exists: Checks if a table exists in the database
  - _record_exists: Checks if a record exists in a table
- Implemented connection management methods:
  - get_connection: Establishes a connection to the database
  - close_connection: Closes the database connection
  - drop_database: Drops the database
- Implemented schema creation method:
  - create_database_schema: Creates the database schema

## Untouched Nodes
The following methods still need to be implemented:
- execute_query: Execute SQL queries
- create_table: Create a table
- drop_table: Drop a table
- insert_record: Insert a record
- update_record: Update a record
- delete_record: Delete a record
- load_from_csv: Load data from CSV
- create_index: Create an index
- drop_index: Drop an index

# Next Steps
In the next iteration, I'll implement:
1. execute_query method
2. table operations (create_table, drop_table)
3. record operations (insert_record, update_record, delete_record)

## Next to Plan
- execute_query
- create_table
- drop_table
- insert_record
- update_record
- delete_record

## Difficulty
Medium - The next methods involve SQL query construction and error handling, but the retry logic and connection management are already in place.
---------------------------------------------

Give an overall rating of the output that also considers the review. The review must be one of the following three values: 'certainly correct', 'uncertain', or 'certainly wrong'

Wrap your answer into a <rating> tag, i.e.:

<rating>
'certainly correct', 'uncertain', or 'certainly wrong'
</rating>

********************

I have a high-level design doc and want to turn it into code using LLMs. I chain together several LLM calls to achieve this, were I first have a planning phase and then a transpilation phase.

Below are an outputs and review for one of the steps. Based on the output and the review, I want you to label the step's correctness as either 'certainly correct', 'uncertain', or 'certainly wrong'.

Your rating must only contain one of these three values. This is how you should assign them:

1. 'certainly correct': Based on code and review, the step produced an output that is certainly correct and will not cause any problems further down the transpilation process.

2. 'uncertain': It is hard to tell whether the output is correct or incorrect.

3. 'certainly incorrect': Based on code and review, the step produced an output that is certainly incorrect as is. The problems might be fixable in the future but the current output is erreneous, either by being too vague, underspecified or producing wrong code (e.g., code that doesn't compile).

Here is the LLM's output:
---------------------------------------------
def execute_query(connection, query: str, params: t.Optional[t.Dict] = None) -> t.List[t.Dict]:
    '''
    Execute a SQL query with optional parameters and return the results.
    
    Args:
        connection: Database connection
        query: SQL query to execute
        params: Optional parameters for the query
        
    Returns:
        List of dictionaries representing the query results
    '''
    cursor = connection.cursor(row_factory=psycopg.rows.dict_row)
    try:
        if params:
            cursor.execute(query, params)
        else:
            cursor.execute(query)
        
        # For SELECT queries, return the results
        if query.strip().upper().startswith("SELECT"):
            return cursor.fetchall()
        # For other queries, commit the changes and return empty list
        else:
            connection.commit()
            return []
    except Exception as e:
        connection.rollback()
        logging.error(f"Error executing query: {query}, error: {str(e)}")
        raise

def create_table(connection, table):
    '''
    Create a table in the database based on a BaseTable object.
    
    Args:
        connection: Database connection
        table: BaseTable object representing the table to create
    '''
    # Get the SQL statement to create the table
    create_table_sql = table.get_create_table_sql()
    
    # Execute the SQL statement
    try:
        execute_query(connection, create_table_sql)
        logging.info(f"Table {table.name} created successfully")
    except Exception as e:
        logging.error(f"Error creating table {table.name}: {str(e)}")
        raise

def drop_table(connection, table_name: str):
    '''
    Drop a table from the database if it exists.
    
    Args:
        connection: Database connection
        table_name: Name of the table to drop
    '''
    try:
        # Check if the table exists before attempting to drop it
        if _table_exists(connection, table_name):
            execute_query(connection, f"DROP TABLE {table_name}")
            logging.info(f"Table {table_name} dropped successfully")
        else:
            logging.info(f"Table {table_name} does not exist, no need to drop")
    except Exception as e:
        logging.error(f"Error dropping table {table_name}: {str(e)}")
        raise

def insert_record(connection, table_name: str, record: t.Dict):
    '''
    Insert a record into a table.
    
    Args:
        connection: Database connection
        table_name: Name of the table to insert into
        record: Dictionary containing column names and values
    
    Returns:
        The ID of the inserted record
    '''
    # Ensure the table exists
    if not _table_exists(connection, table_name):
        raise ValueError(f"Table {table_name} does not exist")
    
    # Prepare column names and placeholders for values
    columns = list(record.keys())
    placeholders = [f"%({col})s" for col in columns]
    
    # Construct the SQL query
    query = f"INSERT INTO {table_name} ({', '.join(columns)}) VALUES ({', '.join(placeholders)}) RETURNING id"
    
    try:
        # Execute the query and return the ID of the inserted record
        result = execute_query(connection, query, record)
        if result and len(result) > 0:
            return result[0]['id']
        return None
    except Exception as e:
        logging.error(f"Error inserting record into {table_name}: {str(e)}")
        raise

def update_record(connection, table_name: str, record_id: int, record: t.Dict):
    '''
    Update a record in a table.
    
    Args:
        connection: Database connection
        table_name: Name of the table to update
        record_id: ID of the record to update
        record: Dictionary containing column names and values to update
    
    Returns:
        True if the record was updated, False otherwise
    '''
    # Ensure the table exists
    if not _table_exists(connection, table_name):
        raise ValueError(f"Table {table_name} does not exist")
    
    # Ensure the record exists
    if not _record_exists(connection, table_name, record_id):
        return False
    
    # Prepare SET clause
    set_clause = ", ".join([f"{col} = %({col})s" for col in record.keys()])
    
    # Add the ID to the parameters
    params = record.copy()
    params['id'] = record_id
    
    # Construct the SQL query
    query = f"UPDATE {table_name} SET {set_clause} WHERE id = %(id)s"
    
    try:
        # Execute the query
        execute_query(connection, query, params)
        return True
    except Exception as e:
        logging.error(f"Error updating record in {table_name}: {str(e)}")
        raise

def delete_record(connection, table_name: str, record_id: int):
    '''
    Delete a record from a table.
    
    Args:
        connection: Database connection
        table_name: Name of the table to delete from
        record_id: ID of the record to delete
    
    Returns:
        True if the record was deleted, False otherwise
    '''
    # Ensure the table exists
    if not _table_exists(connection, table_name):
        raise ValueError(f"Table {table_name} does not exist")
    
    # Ensure the record exists
    if not _record_exists(connection, table_name, record_id):
        return False
    
    # Construct the SQL query
    query = f"DELETE FROM {table_name} WHERE id = %(id)s"
    
    try:
        # Execute the query
        execute_query(connection, query, {'id': record_id})
        return True
    except Exception as e:
        logging.error(f"Error deleting record from {table_name}: {str(e)}")
        raise
---------------------------------------------

Here is the review to this output:
---------------------------------------------
# Performed Steps
In this iteration, I've implemented:
1. execute_query method for executing SQL queries
2. Table operations (create_table, drop_table)
3. Record operations (insert_record, update_record, delete_record)

## Full Completions
- Implemented execute_query: Executes SQL queries with parameters
- Implemented create_table: Creates a table based on a BaseTable object
- Implemented drop_table: Drops a table if it exists
- Implemented insert_record: Inserts a record into a table
- Implemented update_record: Updates a record in a table
- Implemented delete_record: Deletes a record from a table

## Untouched Nodes
The following methods still need to be implemented:
- load_from_csv: Load data from CSV
- create_index: Create an index
- drop_index: Drop an index

# Next Steps
In the next iteration, I'll implement:
1. load_from_csv method
2. Index operations (create_index, drop_index)

## Next to Plan
- load_from_csv
- create_index
- drop_index

## Difficulty
Easy - The remaining methods are straightforward implementations that follow similar patterns to the ones already implemented.
---------------------------------------------

Give an overall rating of the output that also considers the review. The review must be one of the following three values: 'certainly correct', 'uncertain', or 'certainly wrong'

Wrap your answer into a <rating> tag, i.e.:

<rating>
'certainly correct', 'uncertain', or 'certainly wrong'
</rating>

********************

I have a high-level design doc and want to turn it into code using LLMs. I chain together several LLM calls to achieve this, were I first have a planning phase and then a transpilation phase.

Below are an outputs and review for one of the steps. Based on the output and the review, I want you to label the step's correctness as either 'certainly correct', 'uncertain', or 'certainly wrong'.

Your rating must only contain one of these three values. This is how you should assign them:

1. 'certainly correct': Based on code and review, the step produced an output that is certainly correct and will not cause any problems further down the transpilation process.

2. 'uncertain': It is hard to tell whether the output is correct or incorrect.

3. 'certainly incorrect': Based on code and review, the step produced an output that is certainly incorrect as is. The problems might be fixable in the future but the current output is erreneous, either by being too vague, underspecified or producing wrong code (e.g., code that doesn't compile).

Here is the LLM's output:
---------------------------------------------
class DBOperationsInterface:
    '''Interface for database operations'''
    
    def get_connection(self):
        '''Get a connection to the database'''
        pass
        
    def close_connection(self, connection):
        '''Close a connection to the database'''
        pass
        
    def drop_database(self):
        '''Drop the database'''
        pass
        
    def create_database_schema(self, schema: Schema):
        '''Create the database schema'''
        pass
        
    def execute_query(self, connection, query: str, params: t.Optional[t.Dict] = None) -> t.List[t.Dict]:
        '''Execute a SQL query with optional parameters and return the results'''
        pass
        
    def create_table(self, connection, table):
        '''Create a table in the database'''
        pass
        
    def drop_table(self, connection, table_name: str):
        '''Drop a table from the database'''
        pass
        
    def insert_record(self, connection, table_name: str, record: t.Dict):
        '''Insert a record into a table'''
        pass
        
    def update_record(self, connection, table_name: str, record_id: int, record: t.Dict):
        '''Update a record in a table'''
        pass
        
    def delete_record(self, connection, table_name: str, record_id: int):
        '''Delete a record from a table'''
        pass
        
    def load_from_csv(self, connection, table_name: str, csv_file_path: str, delimiter: str = ','):
        '''Load data from a CSV file into a table'''
        pass
        
    def create_index(self, connection, table_name: str, column_name: str, index_name: str = None, unique: bool = False):
        '''Create an index on a table column'''
        pass
        
    def drop_index(self, connection, index_name: str):
        '''Drop an index'''
        pass


class PostgresOperations(DBOperationsInterface):
    '''Implementation of database operations for PostgreSQL'''
    
    def __init__(self, host: str, port: int, dbname: str, user: str, password: str):
        '''Initialize the PostgreSQL operations'''
        self.host = host
        self.port = port
        self.dbname = dbname
        self.user = user
        self.password = password
        self.max_retries = 3
        self.retry_delay = 2  # seconds
        
    def get_connection(self):
        '''
        Get a connection to the PostgreSQL database with retry logic.
        
        Returns:
            Database connection object
        '''
        retries = 0
        while retries < self.max_retries:
            try:
                connection = psycopg.connect(
                    host=self.host,
                    port=self.port,
                    dbname=self.dbname,
                    user=self.user,
                    password=self.password
                )
                return connection
            except Exception as e:
                retries += 1
                if retries >= self.max_retries:
                    logging.error(f"Failed to connect to database after {self.max_retries} attempts: {str(e)}")
                    raise
                logging.warning(f"Connection attempt {retries} failed, retrying in {self.retry_delay} seconds...")
                time.sleep(self.retry_delay)
    
    def close_connection(self, connection):
        '''
        Close a connection to the database.
        
        Args:
            connection: Database connection to close
        '''
        if connection:
            connection.close()
            
    def drop_database(self):
        '''
        Drop the database if it exists.
        
        Note: This operation is dangerous and should be used with caution.
        '''
        # Connect to the default 'postgres' database to drop the target database
        temp_connection = psycopg.connect(
            host=self.host,
            port=self.port,
            dbname="postgres",
            user=self.user,
            password=self.password
        )
        temp_connection.autocommit = True
        
        try:
            cursor = temp_connection.cursor()
            # Check if database exists
            cursor.execute("SELECT 1 FROM pg_database WHERE datname = %s", (self.dbname,))
            if cursor.fetchone():
                # Terminate all connections to the database
                cursor.execute(f"""
                    SELECT pg_terminate_backend(pg_stat_activity.pid)
                    FROM pg_stat_activity
                    WHERE pg_stat_activity.datname = '{self.dbname}'
                    AND pid <> pg_backend_pid()
                """)
                # Drop the database
                cursor.execute(f"DROP DATABASE {self.dbname}")
                logging.info(f"Database {self.dbname} dropped successfully")
            else:
                logging.info(f"Database {self.dbname} does not exist, no need to drop")
        except Exception as e:
            logging.error(f"Error dropping database {self.dbname}: {str(e)}")
            raise
        finally:
            temp_connection.close()
            
    def create_database_schema(self, schema: Schema):
        '''
        Create the database schema.
        
        Args:
            schema: Schema object containing table definitions
        '''
        connection = self.get_connection()
        try:
            # Create each table in the schema
            for table in schema.tables:
                self.create_table(connection, table)
        finally:
            self.close_connection(connection)

    def _table_exists(self, connection, table_name: str) -> bool:
        '''
        Check if a table exists in the database.
        
        Args:
            connection: Database connection
            table_name: Name of the table to check
            
        Returns:
            True if the table exists, False otherwise
        '''
        query = """
        SELECT 1 FROM information_schema.tables 
        WHERE table_name = %(table_name)s
        """
        result = self.execute_query(connection, query, {'table_name': table_name})
        return len(result) > 0

    def _record_exists(self, connection, table_name: str, record_id: int) -> bool:
        '''
        Check if a record exists in a table.
        
        Args:
            connection: Database connection
            table_name: Name of the table to check
            record_id: ID of the record to check
            
        Returns:
            True if the record exists, False otherwise
        '''
        query = f"SELECT 1 FROM {table_name} WHERE id = %(id)s"
        result = self.execute_query(connection, query, {'id': record_id})
        return len(result) > 0

    def execute_query(self, connection, query: str, params: t.Optional[t.Dict] = None) -> t.List[t.Dict]:
        '''
        Execute a SQL query with optional parameters and return the results.
        
        Args:
            connection: Database connection
            query: SQL query to execute
            params: Optional parameters for the query
            
        Returns:
            List of dictionaries representing the query results
        '''
        cursor = connection.cursor(row_factory=psycopg.rows.dict_row)
        try:
            if params:
                cursor.execute(query, params)
            else:
                cursor.execute(query)
            
            # For SELECT queries, return the results
            if query.strip().upper().startswith("SELECT"):
                return cursor.fetchall()
            # For other queries, commit the changes and return empty list
            else:
                connection.commit()
                return []
        except Exception as e:
            connection.rollback()
            logging.error(f"Error executing query: {query}, error: {str(e)}")
            raise

    def create_table(self, connection, table):
        '''
        Create a table in the database based on a BaseTable object.
        
        Args:
            connection: Database connection
            table: BaseTable object representing the table to create
        '''
        # Get the SQL statement to create the table
        create_table_sql = table.get_create_table_sql()
        
        # Execute the SQL statement
        try:
            self.execute_query(connection, create_table_sql)
            logging.info(f"Table {table.name} created successfully")
        except Exception as e:
            logging.error(f"Error creating table {table.name}: {str(e)}")
            raise

    def drop_table(self, connection, table_name: str):
        '''
        Drop a table from the database if it exists.
        
        Args:
            connection: Database connection
            table_name: Name of the table to drop
        '''
        try:
            # Check if the table exists before attempting to drop it
            if self._table_exists(connection, table_name):
                self.execute_query(connection, f"DROP TABLE {table_name}")
                logging.info(f"Table {table_name} dropped successfully")
            else:
                logging.info(f"Table {table_name} does not exist, no need to drop")
        except Exception as e:
            logging.error(f"Error dropping table {table_name}: {str(e)}")
            raise

    def insert_record(self, connection, table_name: str, record: t.Dict):
        '''
        Insert a record into a table.
        
        Args:
            connection: Database connection
            table_name: Name of the table to insert into
            record: Dictionary containing column names and values
        
        Returns:
            The ID of the inserted record
        '''
        # Ensure the table exists
        if not self._table_exists(connection, table_name):
            raise ValueError(f"Table {table_name} does not exist")
        
        # Prepare column names and placeholders for values
        columns = list(record.keys())
        placeholders = [f"%({col})s" for col in columns]
        
        # Construct the SQL query
        query = f"INSERT INTO {table_name} ({', '.join(columns)}) VALUES ({', '.join(placeholders)}) RETURNING id"
        
        try:
            # Execute the query and return the ID of the inserted record
            result = self.execute_query(connection, query, record)
            if result and len(result) > 0:
                return result[0]['id']
            return None
        except Exception as e:
            logging.error(f"Error inserting record into {table_name}: {str(e)}")
            raise

    def update_record(self, connection, table_name: str, record_id: int, record: t.Dict):
        '''
        Update a record in a table.
        
        Args:
            connection: Database connection
            table_name: Name of the table to update
            record_id: ID of the record to update
            record: Dictionary containing column names and values to update
        
        Returns:
            True if the record was updated, False otherwise
        '''
        # Ensure the table exists
        if not self._table_exists(connection, table_name):
            raise ValueError(f"Table {table_name} does not exist")
        
        # Ensure the record exists
        if not self._record_exists(connection, table_name, record_id):
            return False
        
        # Prepare SET clause
        set_clause = ", ".join([f"{col} = %({col})s" for col in record.keys()])
        
        # Add the ID to the parameters
        params = record.copy()
        params['id'] = record_id
        
        # Construct the SQL query
        query = f"UPDATE {table_name} SET {set_clause} WHERE id = %(id)s"
        
        try:
            # Execute the query
            self.execute_query(connection, query, params)
            return True
        except Exception as e:
            logging.error(f"Error updating record in {table_name}: {str(e)}")
            raise

    def delete_record(self, connection, table_name: str, record_id: int):
        '''
        Delete a record from a table.
        
        Args:
            connection: Database connection
            table_name: Name of the table to delete from
            record_id: ID of the record to delete
        
        Returns:
            True if the record was deleted, False otherwise
        '''
        # Ensure the table exists
        if not self._table_exists(connection, table_name):
            raise ValueError(f"Table {table_name} does not exist")
        
        # Ensure the record exists
        if not self._record_exists(connection, table_name, record_id):
            return False
        
        # Construct the SQL query
        query = f"DELETE FROM {table_name} WHERE id = %(id)s"
        
        try:
            # Execute the query
            self.execute_query(connection, query, {'id': record_id})
            return True
        except Exception as e:
            logging.error(f"Error deleting record from {table_name}: {str(e)}")
            raise

    def load_from_csv(self, connection, table_name: str, csv_file_path: str, delimiter: str = ','):
        '''
        Load data from a CSV file into a table.
        
        Args:
            connection: Database connection
            table_name: Name of the table to load data into
            csv_file_path: Path to the CSV file
            delimiter: CSV delimiter character (default: ',')
        
        Returns:
            Number of records inserted
        '''
        # Ensure the table exists
        if not self._table_exists(connection, table_name):
            raise ValueError(f"Table {table_name} does not exist")
        
        records_inserted = 0
        
        try:
            # Open and read the CSV file
            with open(csv_file_path, 'r', newline='') as csvfile:
                reader = csv.DictReader(csvfile, delimiter=delimiter)
                
                # Get column names from the CSV header
                columns = reader.fieldnames
                
                # For each row in the CSV, insert a record
                for row in reader:
                    # Clean up the row data (remove empty strings, convert to appropriate types)
                    clean_row = {k: (v if v != '' else None) for k, v in row.items()}
                    
                    # Insert the record
                    self.insert_record(connection, table_name, clean_row)
                    records_inserted += 1
                    
            logging.info(f"Successfully loaded {records_inserted} records into {table_name} from {csv_file_path}")
            return records_inserted
        except Exception as e:
            logging.error(f"Error loading data from CSV into {table_name}: {str(e)}")
            raise

    def create_index(self, connection, table_name: str, column_name: str, index_name: str = None, unique: bool = False):
        '''
        Create an index on a table column.
        
        Args:
            connection: Database connection
            table_name: Name of the table
            column_name: Name of the column to index
            index_name: Name of the index (default: table_name_column_name_idx)
            unique: Whether the index should enforce uniqueness (default: False)
        '''
        # Ensure the table exists
        if not self._table_exists(connection, table_name):
            raise ValueError(f"Table {table_name} does not exist")
        
        # Generate index name if not provided
        if index_name is None:
            index_name = f"{table_name}_{column_name}_idx"
        
        # Construct the SQL query
        unique_str = "UNIQUE " if unique else ""
        query = f"CREATE {unique_str}INDEX IF NOT EXISTS {index_name} ON {table_name} ({column_name})"
        
        try:
            # Execute the query
            self.execute_query(connection, query)
            logging.info(f"Successfully created index {index_name} on {table_name}.{column_name}")
        except Exception as e:
            logging.error(f"Error creating index on {table_name}.{column_name}: {str(e)}")
            raise

    def drop_index(self, connection, index_name: str):
        '''
        Drop an index if it exists.
        
        Args:
            connection: Database connection
            index_name: Name of the index to drop
        '''
        # Check if the index exists
        query = """
        SELECT 1 FROM pg_indexes WHERE indexname = %(index_name)s
        """
        
        try:
            result = self.execute_query(connection, query, {'index_name': index_name})
            
            if result and len(result) > 0:
                # Index exists, drop it
                drop_query = f"DROP INDEX {index_name}"
                self.execute_query(connection, drop_query)
                logging.info(f"Successfully dropped index {index_name}")
            else:
                logging.info(f"Index {index_name} does not exist, no need to drop")
        except Exception as e:
            logging.error(f"Error dropping index {index_name}: {str(e)}")
            raise
---------------------------------------------

Here is the review to this output:
---------------------------------------------
# Performed Steps
I've identified the issues with the current implementation and will fix them:

1. Removed duplicate standalone functions at the top of the file that implement the same functionality as methods in the PostgresOperations class.
2. Implemented all the methods in the PostgresOperations class that were marked with 'pass'.
3. Ensured consistent signatures and behaviors between methods.

## Full Completions
- Implemented all methods in the PostgresOperations class:
  - execute_query
  - create_table
  - drop_table
  - insert_record
  - update_record
  - delete_record
  - load_from_csv
  - create_index
  - drop_index

## Untouched Nodes
None - All methods have been implemented.

# Next Steps
The file is now fully implemented. All required methods have been completed in the appropriate classes.

## Difficulty
Easy - The implementation was straightforward as it mainly involved moving the standalone function implementations into the class methods.
---------------------------------------------

Give an overall rating of the output that also considers the review. The review must be one of the following three values: 'certainly correct', 'uncertain', or 'certainly wrong'

Wrap your answer into a <rating> tag, i.e.:

<rating>
'certainly correct', 'uncertain', or 'certainly wrong'
</rating>

********************

I have a high-level design doc and want to turn it into code using LLMs. I chain together several LLM calls to achieve this, were I first have a planning phase and then a transpilation phase.

Below are an outputs and review for one of the steps. Based on the output and the review, I want you to label the step's correctness as either 'certainly correct', 'uncertain', or 'certainly wrong'.

Your rating must only contain one of these three values. This is how you should assign them:

1. 'certainly correct': Based on code and review, the step produced an output that is certainly correct and will not cause any problems further down the transpilation process.

2. 'uncertain': It is hard to tell whether the output is correct or incorrect.

3. 'certainly incorrect': Based on code and review, the step produced an output that is certainly incorrect as is. The problems might be fixable in the future but the current output is erreneous, either by being too vague, underspecified or producing wrong code (e.g., code that doesn't compile).

Here is the LLM's output:
---------------------------------------------
import psycopg
import logging
import time
import typing as t
import csv
from database.schema import Schema


class DBOperationsInterface:
    """
    Interface for defining all database related operations to backup the CRM.
    """
    def __init__(self,
                 db_name: str,
                 schema: Schema,
                 host: str,
                 port: str,
                 user: str,
                 password: str,
                 max_retry: int = 3,
                 timeout_s: int = 200):
        """
        Feel free to add any other attributes you think may be useful
        """
        self.db_name = db_name
        self.schema = schema
        self.host = host
        self.port = port
        self.user = user
        self.password = password
        self.max_retry = max_retry
        self.timeout_s = timeout_s
        self.conn = None

    def get_connection(self) -> bool:
        """
        Using psycopg package to create a database connection to database named self.db_name.
        """
        raise NotImplementedError('Inherit me!')

    def close_connection(self) -> bool:
        """
        close the psycopg connection in self.conn and set it to None
        """
        raise NotImplementedError('Inherit me!')

    def create_database_schema(self) -> bool:
        """
        Execute SQL query to load the database schema.
        """
        raise NotImplementedError('Inherit me!')

    def execute_query(self, query: str):
        """
        Execute the SQL query provided and return the results.
        """
        raise NotImplementedError('Inherit me!')

    def create_table(self, table_name: str) -> bool:
        """
        Execute this SQL query to create table. Do not do anything if the table exists.
        """
        raise NotImplementedError('Inherit me!')

    def drop_table(self, table_name: str) -> bool:
        """
        Execute this SQL query to drop an existing table.
        """
        raise NotImplementedError('Inherit me!')

    def insert_record(self, table_name: str, record: t.List[t.Any]) -> bool:
        """
        Insert one record into table.
        """
        raise NotImplementedError('Inherit me!')

    def update_record(self, table_name: str, record: t.List[t.Any]) -> bool:
        """
        Update one record in the table.
        """
        raise NotImplementedError('Inherit me!')

    def delete_record(self, table_name: str, record_id: int) -> bool:
        """
        Delete record with record_id in the table.
        """
        raise NotImplementedError('Inherit me!')

    def load_from_csv(self, table_name: str, csv_path: str, sep: str = '|', header: bool = False) -> bool:
        """
        Load a batch of records from csv.
        """
        raise NotImplementedError('Inherit me!')

    def create_index(self, index_name: str, table_name: str, col_names: t.List[str]) -> bool:
        """
        Create an index with name index_name on table (table_name) over a list of columns (col_names).
        """
        raise NotImplementedError('Inherit me!')

    def drop_index(self, index_name: str) -> bool:
        """
        Write and execute an SQL in Postgres syntax to drop an index.
        """
        raise NotImplementedError('Inherit me!')


class PostgresOperations(DBOperationsInterface):
    """
    Interface for defining all database related operations to backup the CRM.
    """

    def __init__(self,
                 db_name: str,
                 schema: Schema,
                 host: str,
                 port: str,
                 user: str,
                 password: str,
                 max_retry: int = 3,
                 timeout_s: int = 200):
        """
        Initialize PostgreSQL operations with connection parameters
        """
        super().__init__(db_name, schema, host, port, user, password, max_retry, timeout_s)
        self.logger = logging.getLogger(__name__)

    def get_connection(self) -> bool:
        """
        Using psycopg package to create a database connection to database named self.db_name.
        If self.db_name does not exist, you should first connect to admin database with name 'postgres',
        create a database with name self.db_name, and then connect to self.db_name.
        Set it as self.conn
        Hint: You can set conn.autocommit = True to avoid commit transaction every time
         after setting the connection, you should set the timeout in seconds as self._timeout_s,
        Returns:
            bool: True if successfully connected, False otherwise.
        """
        try:
            # Try to connect to the specified database
            self.conn = psycopg.connect(
                host=self.host,
                port=self.port,
                dbname=self.db_name,
                user=self.user,
                password=self.password,
                connect_timeout=self.timeout_s
            )
            self.conn.autocommit = True
            return True
        except psycopg.errors.OperationalError as e:
            # If database doesn't exist, connect to postgres and create it
            if "database" in str(e) and "does not exist" in str(e):
                try:
                    # Connect to postgres database
                    admin_conn = psycopg.connect(
                        host=self.host,
                        port=self.port,
                        dbname="postgres",
                        user=self.user,
                        password=self.password,
                        connect_timeout=self.timeout_s
                    )
                    admin_conn.autocommit = True
                    
                    # Create the database
                    with admin_conn.cursor() as cursor:
                        cursor.execute(f"CREATE DATABASE {self.db_name}")
                    
                    admin_conn.close()
                    
                    # Now connect to the newly created database
                    self.conn = psycopg.connect(
                        host=self.host,
                        port=self.port,
                        dbname=self.db_name,
                        user=self.user,
                        password=self.password,
                        connect_timeout=self.timeout_s
                    )
                    self.conn.autocommit = True
                    return True
                except Exception as create_ex:
                    self.logger.error(f"Failed to create database: {str(create_ex)}")
                    return False
            else:
                self.logger.error(f"Failed to connect to database: {str(e)}")
                return False
        except Exception as e:
            self.logger.error(f"Unexpected error connecting to database: {str(e)}")
            return False

    def close_connection(self) -> bool:
        """
        close the psycopg connection in self.conn and set it to None
        Returns:
            bool: True if successfully closed connection, False otherwise.
        """
        try:
            if self.conn is not None:
                self.conn.close()
                self.conn = None
            return True
        except Exception as e:
            self.logger.error(f"Error closing connection: {str(e)}")
            return False

    def create_database_schema(self) -> bool:
        """
        Execute SQL query (self.schema.schema_sql_statement) to create the database schema.
        Returns:
            bool: True if successfully created schema, False otherwise.
        """
        if self.conn is None and not self.get_connection():
            return False
            
        try:
            # Execute the schema SQL statement
            with self.conn.cursor() as cursor:
                cursor.execute(self.schema.schema_sql_statement)
            return True
        except Exception as e:
            self.logger.error(f"Error creating database schema: {str(e)}")
            return False

    def drop_database(self) -> bool:
        """
        Drop self.db_name database,
        You should create a connection to admin database with name 'postgres', then write SQL in Postgres-syntax to
        drop this database.
        Close connection
        Returns:
            bool: True if successfully dropped, False otherwise.
        """
        try:
            # Close current connection if exists
            if self.conn is not None:
                self.conn.close()
                self.conn = None
                
            # Connect to postgres database
            admin_conn = psycopg.connect(
                host=self.host,
                port=self.port,
                dbname="postgres",
                user=self.user,
                password=self.password,
                connect_timeout=self.timeout_s
            )
            admin_conn.autocommit = True
            
            # Terminate all connections to the database
            with admin_conn.cursor() as cursor:
                cursor.execute(f"""
                    SELECT pg_terminate_backend(pg_stat_activity.pid)
                    FROM pg_stat_activity
                    WHERE pg_stat_activity.datname = '{self.db_name}'
                    AND pid <> pg_backend_pid()
                """)
                
                # Drop the database
                cursor.execute(f"DROP DATABASE IF EXISTS {self.db_name}")
                
            admin_conn.close()
            return True
        except Exception as e:
            self.logger.error(f"Error dropping database: {str(e)}")
            return False

    def _execute_with_retry(self, query: str, params: t.Optional[t.List] = None) -> t.Optional[t.Any]:
        """
        Helper method to execute a query with retry logic.
        
        Args:
            query: SQL query to execute
            params: Parameters for the query
            
        Returns:
            Query results or None if execution failed
        """
        retry_count = 0
        while retry_count < self.max_retry:
            try:
                if self.conn is None and not self.get_connection():
                    self.logger.error("Failed to get connection")
                    return None
                    
                with self.conn.cursor() as cursor:
                    if params:
                        cursor.execute(query, params)
                    else:
                        cursor.execute(query)
                    
                    try:
                        results = cursor.fetchall()
                        return results
                    except psycopg.ProgrammingError:
                        # No results to fetch (e.g., for INSERT, UPDATE, DELETE)
                        return []
            except Exception as e:
                self.logger.error(f"Error executing query (attempt {retry_count+1}): {str(e)}")
                retry_count += 1
                if retry_count >= self.max_retry:
                    return None
                time.sleep(1)  # Sleep for 1 second before retrying
        
        return None

    def execute_query(self, query: str) -> t.Any:
        """
        Execute the SQL query provided and return the results.
        If execution not successful, you should sleep for 1s and try again. There are at most self.max_retry number of retrys.
        Hint: you should get connection if connection is closed. Use self._execute_with_retry helper function
        Returns:
            results: return the results of this query, None if execution not successful.
        """
        return self._execute_with_retry(query)

    def _table_exists(self, table_name: str) -> bool:
        """
        Check if a table exists in the database.
        
        Args:
            table_name: Name of the table to check
            
        Returns:
            True if the table exists, False otherwise
        """
        query = """
        SELECT 1 FROM information_schema.tables 
        WHERE table_schema = 'public' AND table_name = %s
        """
        result = self._execute_with_retry(query, [table_name])
        return result is not None and len(result) > 0

    def _record_exists(self, table_name: str, record_id: int) -> bool:
        """
        Check if a record exists in a table.
        
        Args:
            table_name: Name of the table to check
            record_id: ID of the record to check
            
        Returns:
            True if the record exists, False otherwise
        """
        # Get the primary key column name
        primary_key = self.schema.table_dictionary[table_name].primary_key[0]
        
        query = f"SELECT 1 FROM {table_name} WHERE {primary_key} = %s"
        result = self._execute_with_retry(query, [record_id])
        return result is not None and len(result) > 0

    def create_table(self, table_name: str) -> bool:
        """
        Execute the SQL query to create table. Do not do anything if the table exists.
        The create table sql statement can be found in self.schema.table_dictionary[table_name]
        Returns:
            bool: True if successfully created table, False otherwise.
        """
        if self._table_exists(table_name):
            self.logger.info(f"Table {table_name} already exists")
            return True
            
        try:
            table = self.schema.table_dictionary.get(table_name)
            if not table:
                self.logger.error(f"Table {table_name} not found in schema")
                return False
                
            create_table_sql = table.get_create_table_sql()
            result = self._execute_with_retry(create_table_sql)
            return result is not None
        except Exception as e:
            self.logger.error(f"Error creating table {table_name}: {str(e)}")
            return False

    def drop_table(self, table_name: str) -> bool:
        """
        Execute this SQL query to drop a table if exists.
        Returns:
            bool: True if successfully dropped schema, False otherwise.
        """
        try:
            query = f"DROP TABLE IF EXISTS {table_name}"
            result = self._execute_with_retry(query)
            return result is not None
        except Exception as e:
            self.logger.error(f"Error dropping table {table_name}: {str(e)}")
            return False

    def insert_record(self, table_name: str, record: t.List[t.Any]) -> bool:
        """
        Insert one record into table.
        Should check if the table_name exists (raise appropriate error otherwise),
        Then write and execute an SQL in Postgres syntax to insert this record.
        Note that your SQL statement should check if record id (record[0]) already exists, insert this tuple if it does not exist.
        If this tuple already exist, call self.update_record(table_name, record) instead.
        If execution not successful, you should sleep for 0.1s and try again. There are at most self.max_retry number of retrys.
        Returns:
            bool: True if successfully inserted record, False otherwise.
        """
        if not self._table_exists(table_name):
            self.logger.error(f"Table {table_name} does not exist")
            return False
            
        # Get table information
        table = self.schema.table_dictionary[table_name]
        primary_key = table.primary_key[0]
        columns = table.columns
        
        # Check if record with this ID already exists
        record_id = record[0]
        if self._record_exists(table_name, record_id):
            # Record exists, update it instead
            return self.update_record(table_name, record)
            
        # Prepare column names and placeholders
        column_names = ", ".join(columns)
        placeholders = ", ".join(["%s" for _ in range(len(record))])
        
        # Construct the query
        query = f"INSERT INTO {table_name} ({column_names}) VALUES ({placeholders})"
        
        # Execute with retry
        retry_count = 0
        while retry_count < self.max_retry:
            try:
                if self.conn is None and not self.get_connection():
                    return False
                    
                with self.conn.cursor() as cursor:
                    cursor.execute(query, record)
                return True
            except Exception as e:
                self.logger.error(f"Error inserting record (attempt {retry_count+1}): {str(e)}")
                retry_count += 1
                if retry_count >= self.max_retry:
                    return False
                time.sleep(0.1)  # Sleep for 0.1 second before retrying
                
        return False

    def update_record(self, table_name: str, record: t.List[t.Any]) -> bool:
        """
        Update one record in the table.
        The id of the record is defined as the first element in record, i.e., record[0]
        You should first check if this id appears in the table in the database.
        If not, call insert_record() and return.
        Then write and execute an SQL in Postgres syntax to update this record with the id.
        In the case where record id is not found in the table, insert this record using insert_record().
        If execution not successful, you should sleep for 0.1s and try again. There are at most self.max_retry number of retrys.
        Note: the column name for id attributes as self.schema.table_dictionary[table_name].primary_key[0]
        Returns:
            bool: True if successfully updated record, False otherwise.
        """
        if not self._table_exists(table_name):
            self.logger.error(f"Table {table_name} does not exist")
            return False
            
        # Get table information
        table = self.schema.table_dictionary[table_name]
        primary_key = table.primary_key[0]
        columns = table.columns
        
        # Check if record with this ID exists
        record_id = record[0]
        if not self._record_exists(table_name, record_id):
            # Record doesn't exist, insert it instead
            return self.insert_record(table_name, record)
            
        # Prepare SET clause
        set_clauses = []
        for i, col in enumerate(columns):
            if i > 0:  # Skip the primary key (first column)
                set_clauses.append(f"{col} = %s")
                
        set_clause = ", ".join(set_clauses)
        
        # Construct the query
        query = f"UPDATE {table_name} SET {set_clause} WHERE {primary_key} = %s"
        
        # Prepare parameters: all values except primary key, followed by primary key for WHERE clause
        params = record[1:] + [record[0]]
        
        # Execute with retry
        retry_count = 0
        while retry_count < self.max_retry:
            try:
                if self.conn is None and not self.get_connection():
                    return False
                    
                with self.conn.cursor() as cursor:
                    cursor.execute(query, params)
                return True
            except Exception as e:
                self.logger.error(f"Error updating record (attempt {retry_count+1}): {str(e)}")
                retry_count += 1
                if retry_count >= self.max_retry:
                    return False
                time.sleep(0.1)  # Sleep for 0.1 second before retrying
                
        return False

    def delete_record(self, table_name: str, record_id: int) -> bool:
        """
        Delete record with record_id in the table.
        Then write and execute an SQL in Postgres syntax to delete this record with the id.
        Note: the column name for id attributes as self.schema.table_dictionary[table_name].primary_key[0]
        If execution not successful, you should sleep for 0.1s and try again. There are at most self.max_retry number of retrys.
        Returns:
            bool: True if successfully deleted record, False otherwise.
        """
        if not self._table_exists(table_name):
            self.logger.error(f"Table {table_name} does not exist")
            return False
            
        # Get primary key column name
        primary_key = self.schema.table_dictionary[table_name].primary_key[0]
        
        # Check if record exists
        if not self._record_exists(table_name, record_id):
            self.logger.info(f"Record with ID {record_id} does not exist in table {table_name}")
            return True  # Consider it a success if the record doesn't exist
            
        # Construct the query
        query = f"DELETE FROM {table_name} WHERE {primary_key} = %s"
        
        # Execute with retry
        retry_count = 0
        while retry_count < self.max_retry:
            try:
                if self.conn is None and not self.get_connection():
                    return False
                    
                with self.conn.cursor() as cursor:
                    cursor.execute(query, [record_id])
                return True
            except Exception as e:
                self.logger.error(f"Error deleting record (attempt {retry_count+1}): {str(e)}")
                retry_count += 1
                if retry_count >= self.max_retry:
                    return False
                time.sleep(0.1)  # Sleep for 0.1 second before retrying
                
        return False

    def load_from_csv(self, table_name: str, csv_path: str, sep: str = '|', header: bool = False) -> bool:
        """
        Load a batch of records from csv.
        Should check if the table_name exists,
        then write and execute an SQL in Postgres syntax to load all records from this csv.
        Additional arguments, such as sep, header are the arguments related to CSV loading.
        You should expand the function input to include more such arguments with their default value.
        Returns:
            bool: True if successfully loaded, False otherwise.
        """
        if not self._table_exists(table_name):
            self.logger.error(f"Table {table_name} does not exist")
            return False
            
        try:
            # Get table columns
            table = self.schema.table_dictionary[table_name]
            columns = table.columns
            
            # Read CSV file
            records = []
            with open(csv_path, 'r', newline='') as csvfile:
                if header:
                    # Skip header row
                    next(csvfile)
                    
                csv_reader = csv.reader(csvfile, delimiter=sep)
                for row in csv_reader:
                    # Convert empty strings to None
                    processed_row = [None if val == '' else val for val in row]
                    records.append(processed_row)
            
            # Insert each record
            success = True
            for record in records:
                if not self.insert_record(table_name, record):
                    success = False
                    
            return success
        except Exception as e:
            self.logger.error(f"Error loading data from CSV {csv_path}: {str(e)}")
            return False

    def create_index(self, index_name: str, table_name: str, col_names: t.List[str]) -> bool:
        """
        Create an index with name index_name on table (table_name) over a list of columns (col_names).
        You should write and execute an SQL in Postgres syntax to do create index.
        Check if table_name and col_names exist.
        Remember the common case where col_names has length of 1.
        Returns:
            bool: True if successfully created, False otherwise.
        """
        if not self._table_exists(table_name):
            self.logger.error(f"Table {table_name} does not exist")
            return False
            
        # Verify columns exist in the table
        table = self.schema.table_dictionary[table_name]
        for col in col_names:
            if col not in table.columns:
                self.logger.error(f"Column {col} does not exist in table {table_name}")
                return False
                
        # Construct column list for index
        column_list = ", ".join(col_names)
        
        # Construct the query
        query = f"CREATE INDEX IF NOT EXISTS {index_name} ON {table_name} ({column_list})"
        
        try:
            result = self._execute_with_retry(query)
            return result is not None
        except Exception as e:
            self.logger.error(f"Error creating index {index_name}: {str(e)}")
            return False

    def drop_index(self, index_name: str) -> bool:
        """
        Write and execute an SQL in Postgres syntax to drop an index.
        Returns:
            bool: True if successfully dropped, False otherwise.
        """
        try:
            # Check if index exists
            check_query = """
            SELECT 1 FROM pg_indexes WHERE indexname = %s
            """
            result = self._execute_with_retry(check_query, [index_name])
            
            if result and len(result) > 0:
                # Index exists, drop it
                drop_query = f"DROP INDEX {index_name}"
                result = self._execute_with_retry(drop_query)
                return result is not None
            else:
                self.logger.info(f"Index {index_name} does not exist, no need to drop")
                return True
        except Exception as e:
            self.logger.error(f"Error dropping index {index_name}: {str(e)}")
            return False
---------------------------------------------

Here is the review to this output:
---------------------------------------------
# Transpilation Review
The transpilation is not correct. There are several type errors and attribute access issues that need to be fixed.

## Compilation Review
### Failures
1. Type errors with connection assignment and attribute access:
   - Lines 141, 149, 173, 181: Issues with `self.conn` being typed as `None` but assigned a connection object
   - Lines 219, 288, 432, 493, 536: Attempting to access `.cursor()` on potentially `None` objects

2. Missing type parameters:
   - Line 270: `t.List` missing type parameters

3. Attribute access errors:
   - Line 371: `BaseTable` has no attribute `get_create_table_sql`
   - Lines 410, 464, 565, 607: `BaseTable` has no attribute `columns`

### Fixes
1. Fix connection typing by properly annotating `self.conn` in the interface class
2. Add proper type checking before accessing attributes on potentially None objects
3. Add proper type parameters to generic types
4. Fix attribute access on BaseTable by using the correct methods/properties or importing BaseTable

## Dependency Analysis Review
The dependency analysis is incomplete. We need to import `BaseTable` from the appropriate module, as it's referenced in the code but not imported.
---------------------------------------------

Give an overall rating of the output that also considers the review. The review must be one of the following three values: 'certainly correct', 'uncertain', or 'certainly wrong'

Wrap your answer into a <rating> tag, i.e.:

<rating>
'certainly correct', 'uncertain', or 'certainly wrong'
</rating>

********************

I have a high-level design doc and want to turn it into code using LLMs. I chain together several LLM calls to achieve this, were I first have a planning phase and then a transpilation phase.

Below are an outputs and review for one of the steps. Based on the output and the review, I want you to label the step's correctness as either 'certainly correct', 'uncertain', or 'certainly wrong'.

Your rating must only contain one of these three values. This is how you should assign them:

1. 'certainly correct': Based on code and review, the step produced an output that is certainly correct and will not cause any problems further down the transpilation process.

2. 'uncertain': It is hard to tell whether the output is correct or incorrect.

3. 'certainly incorrect': Based on code and review, the step produced an output that is certainly incorrect as is. The problems might be fixable in the future but the current output is erreneous, either by being too vague, underspecified or producing wrong code (e.g., code that doesn't compile).

Here is the LLM's output:
---------------------------------------------
import psycopg
import logging
import time
import typing as t
import csv
from database.schema import Schema, BaseTable


class DBOperationsInterface:
    """
    Interface for defining all database related operations to backup the CRM.
    """
    def __init__(self,
                 db_name: str,
                 schema: Schema,
                 host: str,
                 port: str,
                 user: str,
                 password: str,
                 max_retry: int = 3,
                 timeout_s: int = 200):
        """
        Feel free to add any other attributes you think may be useful
        """
        self.db_name = db_name
        self.schema = schema
        self.host = host
        self.port = port
        self.user = user
        self.password = password
        self.max_retry = max_retry
        self.timeout_s = timeout_s
        self.conn: t.Optional[psycopg.Connection] = None

    def get_connection(self) -> bool:
        """
        Using psycopg package to create a database connection to database named self.db_name.
        """
        raise NotImplementedError('Inherit me!')

    def close_connection(self) -> bool:
        """
        close the psycopg connection in self.conn and set it to None
        """
        raise NotImplementedError('Inherit me!')

    def create_database_schema(self) -> bool:
        """
        Execute SQL query to load the database schema.
        """
        raise NotImplementedError('Inherit me!')

    def execute_query(self, query: str):
        """
        Execute the SQL query provided and return the results.
        """
        raise NotImplementedError('Inherit me!')

    def create_table(self, table_name: str) -> bool:
        """
        Execute this SQL query to create table. Do not do anything if the table exists.
        """
        raise NotImplementedError('Inherit me!')

    def drop_table(self, table_name: str) -> bool:
        """
        Execute this SQL query to drop an existing table.
        """
        raise NotImplementedError('Inherit me!')

    def insert_record(self, table_name: str, record: t.List[t.Any]) -> bool:
        """
        Insert one record into table.
        """
        raise NotImplementedError('Inherit me!')

    def update_record(self, table_name: str, record: t.List[t.Any]) -> bool:
        """
        Update one record in the table.
        """
        raise NotImplementedError('Inherit me!')

    def delete_record(self, table_name: str, record_id: int) -> bool:
        """
        Delete record with record_id in the table.
        """
        raise NotImplementedError('Inherit me!')

    def load_from_csv(self, table_name: str, csv_path: str, sep: str = '|', header: bool = False) -> bool:
        """
        Load a batch of records from csv.
        """
        raise NotImplementedError('Inherit me!')

    def create_index(self, index_name: str, table_name: str, col_names: t.List[str]) -> bool:
        """
        Create an index with name index_name on table (table_name) over a list of columns (col_names).
        """
        raise NotImplementedError('Inherit me!')

    def drop_index(self, index_name: str) -> bool:
        """
        Write and execute an SQL in Postgres syntax to drop an index.
        """
        raise NotImplementedError('Inherit me!')


class PostgresOperations(DBOperationsInterface):
    """
    Interface for defining all database related operations to backup the CRM.
    """

    def __init__(self,
                 db_name: str,
                 schema: Schema,
                 host: str,
                 port: str,
                 user: str,
                 password: str,
                 max_retry: int = 3,
                 timeout_s: int = 200):
        """
        Initialize PostgreSQL operations with connection parameters
        """
        super().__init__(db_name, schema, host, port, user, password, max_retry, timeout_s)
        self.logger = logging.getLogger(__name__)

    def get_connection(self) -> bool:
        """
        Using psycopg package to create a database connection to database named self.db_name.
        If self.db_name does not exist, you should first connect to admin database with name 'postgres',
        create a database with name self.db_name, and then connect to self.db_name.
        Set it as self.conn
        Hint: You can set conn.autocommit = True to avoid commit transaction every time
         after setting the connection, you should set the timeout in seconds as self._timeout_s,
        Returns:
            bool: True if successfully connected, False otherwise.
        """
        try:
            # Try to connect to the specified database
            conn = psycopg.connect(
                host=self.host,
                port=self.port,
                dbname=self.db_name,
                user=self.user,
                password=self.password,
                connect_timeout=self.timeout_s
            )
            conn.autocommit = True
            self.conn = conn
            return True
        except psycopg.errors.OperationalError as e:
            # If database doesn't exist, connect to postgres and create it
            if "database" in str(e) and "does not exist" in str(e):
                try:
                    # Connect to postgres database
                    admin_conn = psycopg.connect(
                        host=self.host,
                        port=self.port,
                        dbname="postgres",
                        user=self.user,
                        password=self.password,
                        connect_timeout=self.timeout_s
                    )
                    admin_conn.autocommit = True
                    
                    # Create the database
                    with admin_conn.cursor() as cursor:
                        cursor.execute(f"CREATE DATABASE {self.db_name}")
                    
                    admin_conn.close()
                    
                    # Now connect to the newly created database
                    conn = psycopg.connect(
                        host=self.host,
                        port=self.port,
                        dbname=self.db_name,
                        user=self.user,
                        password=self.password,
                        connect_timeout=self.timeout_s
                    )
                    conn.autocommit = True
                    self.conn = conn
                    return True
                except Exception as create_ex:
                    self.logger.error(f"Failed to create database: {str(create_ex)}")
                    return False
            else:
                self.logger.error(f"Failed to connect to database: {str(e)}")
                return False
        except Exception as e:
            self.logger.error(f"Unexpected error connecting to database: {str(e)}")
            return False

    def close_connection(self) -> bool:
        """
        close the psycopg connection in self.conn and set it to None
        Returns:
            bool: True if successfully closed connection, False otherwise.
        """
        try:
            if self.conn is not None:
                self.conn.close()
                self.conn = None
            return True
        except Exception as e:
            self.logger.error(f"Error closing connection: {str(e)}")
            return False

    def create_database_schema(self) -> bool:
        """
        Execute SQL query (self.schema.schema_sql_statement) to create the database schema.
        Returns:
            bool: True if successfully created schema, False otherwise.
        """
        if self.conn is None and not self.get_connection():
            return False
            
        try:
            # Execute the schema SQL statement
            if self.conn is not None:
                with self.conn.cursor() as cursor:
                    cursor.execute(self.schema.schema_sql_statement)
                return True
            return False
        except Exception as e:
            self.logger.error(f"Error creating database schema: {str(e)}")
            return False

    def drop_database(self) -> bool:
        """
        Drop self.db_name database,
        You should create a connection to admin database with name 'postgres', then write SQL in Postgres-syntax to
        drop this database.
        Close connection
        Returns:
            bool: True if successfully dropped, False otherwise.
        """
        try:
            # Close current connection if exists
            if self.conn is not None:
                self.conn.close()
                self.conn = None
                
            # Connect to postgres database
            admin_conn = psycopg.connect(
                host=self.host,
                port=self.port,
                dbname="postgres",
                user=self.user,
                password=self.password,
                connect_timeout=self.timeout_s
            )
            admin_conn.autocommit = True
            
            # Terminate all connections to the database
            with admin_conn.cursor() as cursor:
                cursor.execute(f"""
                    SELECT pg_terminate_backend(pg_stat_activity.pid)
                    FROM pg_stat_activity
                    WHERE pg_stat_activity.datname = '{self.db_name}'
                    AND pid <> pg_backend_pid()
                """)
                
                # Drop the database
                cursor.execute(f"DROP DATABASE IF EXISTS {self.db_name}")
                
            admin_conn.close()
            return True
        except Exception as e:
            self.logger.error(f"Error dropping database: {str(e)}")
            return False

    def _execute_with_retry(self, query: str, params: t.Optional[t.List[t.Any]] = None) -> t.Optional[t.List[t.Any]]:
        """
        Helper method to execute a query with retry logic.
        
        Args:
            query: SQL query to execute
            params: Parameters for the query
            
        Returns:
            Query results or None if execution failed
        """
        retry_count = 0
        while retry_count < self.max_retry:
            try:
                if self.conn is None and not self.get_connection():
                    self.logger.error("Failed to get connection")
                    return None
                    
                if self.conn is not None:
                    with self.conn.cursor() as cursor:
                        if params:
                            cursor.execute(query, params)
                        else:
                            cursor.execute(query)
                        
                        try:
                            results = cursor.fetchall()
                            return results
                        except psycopg.ProgrammingError:
                            # No results to fetch (e.g., for INSERT, UPDATE, DELETE)
                            return []
                return None
            except Exception as e:
                self.logger.error(f"Error executing query (attempt {retry_count+1}): {str(e)}")
                retry_count += 1
                if retry_count >= self.max_retry:
                    return None
                time.sleep(1)  # Sleep for 1 second before retrying
        
        return None

    def execute_query(self, query: str) -> t.Any:
        """
        Execute the SQL query provided and return the results.
        If execution not successful, you should sleep for 1s and try again. There are at most self.max_retry number of retrys.
        Hint: you should get connection if connection is closed. Use self._execute_with_retry helper function
        Returns:
            results: return the results of this query, None if execution not successful.
        """
        return self._execute_with_retry(query)

    def _table_exists(self, table_name: str) -> bool:
        """
        Check if a table exists in the database.
        
        Args:
            table_name: Name of the table to check
            
        Returns:
            True if the table exists, False otherwise
        """
        query = """
        SELECT 1 FROM information_schema.tables 
        WHERE table_schema = 'public' AND table_name = %s
        """
        result = self._execute_with_retry(query, [table_name])
        return result is not None and len(result) > 0

    def _record_exists(self, table_name: str, record_id: int) -> bool:
        """
        Check if a record exists in a table.
        
        Args:
            table_name: Name of the table to check
            record_id: ID of the record to check
            
        Returns:
            True if the record exists, False otherwise
        """
        # Get the primary key column name
        table = self.schema.table_dictionary.get(table_name)
        if table is None:
            return False
            
        primary_key = table.primary_key[0]
        
        query = f"SELECT 1 FROM {table_name} WHERE {primary_key} = %s"
        result = self._execute_with_retry(query, [record_id])
        return result is not None and len(result) > 0

    def create_table(self, table_name: str) -> bool:
        """
        Execute the SQL query to create table. Do not do anything if the table exists.
        The create table sql statement can be found in self.schema.table_dictionary[table_name]
        Returns:
            bool: True if successfully created table, False otherwise.
        """
        if self._table_exists(table_name):
            self.logger.info(f"Table {table_name} already exists")
            return True
            
        try:
            table = self.schema.table_dictionary.get(table_name)
            if not table:
                self.logger.error(f"Table {table_name} not found in schema")
                return False
                
            # Assuming BaseTable has a method to get SQL or we can construct it from table attributes
            create_table_sql = f"CREATE TABLE {table_name} ("
            
            # Add columns
            column_defs = []
            for i, col_name in enumerate(table.columns):
                col_type = table.column_types[i]
                column_defs.append(f"{col_name} {col_type}")
                
            # Add primary key
            if table.primary_key:
                pk_cols = ", ".join(table.primary_key)
                column_defs.append(f"PRIMARY KEY ({pk_cols})")
                
            # Add foreign keys
            for fk in table.foreign_keys:
                ref_table = fk.reference_table
                ref_cols = ", ".join(fk.reference_columns)
                cols = ", ".join(fk.columns)
                column_defs.append(f"FOREIGN KEY ({cols}) REFERENCES {ref_table}({ref_cols})")
                
            create_table_sql += ", ".join(column_defs) + ")"
            
            result = self._execute_with_retry(create_table_sql)
            return result is not None
        except Exception as e:
            self.logger.error(f"Error creating table {table_name}: {str(e)}")
            return False

    def drop_table(self, table_name: str) -> bool:
        """
        Execute this SQL query to drop a table if exists.
        Returns:
            bool: True if successfully dropped schema, False otherwise.
        """
        try:
            query = f"DROP TABLE IF EXISTS {table_name}"
            result = self._execute_with_retry(query)
            return result is not None
        except Exception as e:
            self.logger.error(f"Error dropping table {table_name}: {str(e)}")
            return False

    def insert_record(self, table_name: str, record: t.List[t.Any]) -> bool:
        """
        Insert one record into table.
        Should check if the table_name exists (raise appropriate error otherwise),
        Then write and execute an SQL in Postgres syntax to insert this record.
        Note that your SQL statement should check if record id (record[0]) already exists, insert this tuple if it does not exist.
        If this tuple already exist, call self.update_record(table_name, record) instead.
        If execution not successful, you should sleep for 0.1s and try again. There are at most self.max_retry number of retrys.
        Returns:
            bool: True if successfully inserted record, False otherwise.
        """
        if not self._table_exists(table_name):
            self.logger.error(f"Table {table_name} does not exist")
            return False
            
        # Get table information
        table = self.schema.table_dictionary.get(table_name)
        if table is None:
            return False
            
        primary_key = table.primary_key[0]
        
        # Check if record with this ID already exists
        record_id = record[0]
        if self._record_exists(table_name, record_id):
            # Record exists, update it instead
            return self.update_record(table_name, record)
            
        # Prepare column names and placeholders
        column_names = ", ".join(table.columns)
        placeholders = ", ".join(["%s" for _ in range(len(record))])
        
        # Construct the query
        query = f"INSERT INTO {table_name} ({column_names}) VALUES ({placeholders})"
        
        # Execute with retry
        retry_count = 0
        while retry_count < self.max_retry:
            try:
                if self.conn is None and not self.get_connection():
                    return False
                    
                if self.conn is not None:
                    with self.conn.cursor() as cursor:
                        cursor.execute(query, record)
                    return True
                return False
            except Exception as e:
                self.logger.error(f"Error inserting record (attempt {retry_count+1}): {str(e)}")
                retry_count += 1
                if retry_count >= self.max_retry:
                    return False
                time.sleep(0.1)  # Sleep for 0.1 second before retrying
                
        return False

    def update_record(self, table_name: str, record: t.List[t.Any]) -> bool:
        """
        Update one record in the table.
        The id of the record is defined as the first element in record, i.e., record[0]
        You should first check if this id appears in the table in the database.
        If not, call insert_record() and return.
        Then write and execute an SQL in Postgres syntax to update this record with the id.
        In the case where record id is not found in the table, insert this record using insert_record().
        If execution not successful, you should sleep for 0.1s and try again. There are at most self.max_retry number of retrys.
        Note: the column name for id attributes as self.schema.table_dictionary[table_name].primary_key[0]
        Returns:
            bool: True if successfully updated record, False otherwise.
        """
        if not self._table_exists(table_name):
            self.logger.error(f"Table {table_name} does not exist")
            return False
            
        # Get table information
        table = self.schema.table_dictionary.get(table_name)
        if table is None:
            return False
            
        primary_key = table.primary_key[0]
        
        # Check if record with this ID exists
        record_id = record[0]
        if not self._record_exists(table_name, record_id):
            # Record doesn't exist, insert it instead
            return self.insert_record(table_name, record)
            
        # Prepare SET clause
        set_clauses = []
        for i, col in enumerate(table.columns):
            if i > 0:  # Skip the primary key (first column)
                set_clauses.append(f"{col} = %s")
                
        set_clause = ", ".join(set_clauses)
        
        # Construct the query
        query = f"UPDATE {table_name} SET {set_clause} WHERE {primary_key} = %s"
        
        # Prepare parameters: all values except primary key, followed by primary key for WHERE clause
        params = record[1:] + [record[0]]
        
        # Execute with retry
        retry_count = 0
        while retry_count < self.max_retry:
            try:
                if self.conn is None and not self.get_connection():
                    return False
                    
                if self.conn is not None:
                    with self.conn.cursor() as cursor:
                        cursor.execute(query, params)
                    return True
                return False
            except Exception as e:
                self.logger.error(f"Error updating record (attempt {retry_count+1}): {str(e)}")
                retry_count += 1
                if retry_count >= self.max_retry:
                    return False
                time.sleep(0.1)  # Sleep for 0.1 second before retrying
                
        return False

    def delete_record(self, table_name: str, record_id: int) -> bool:
        """
        Delete record with record_id in the table.
        Then write and execute an SQL in Postgres syntax to delete this record with the id.
        Note: the column name for id attributes as self.schema.table_dictionary[table_name].primary_key[0]
        If execution not successful, you should sleep for 0.1s and try again. There are at most self.max_retry number of retrys.
        Returns:
            bool: True if successfully deleted record, False otherwise.
        """
        if not self._table_exists(table_name):
            self.logger.error(f"Table {table_name} does not exist")
            return False
            
        # Get primary key column name
        table = self.schema.table_dictionary.get(table_name)
        if table is None:
            return False
            
        primary_key = table.primary_key[0]
        
        # Check if record exists
        if not self._record_exists(table_name, record_id):
            self.logger.info(f"Record with ID {record_id} does not exist in table {table_name}")
            return True  # Consider it a success if the record doesn't exist
            
        # Construct the query
        query = f"DELETE FROM {table_name} WHERE {primary_key} = %s"
        
        # Execute with retry
        retry_count = 0
        while retry_count < self.max_retry:
            try:
                if self.conn is None and not self.get_connection():
                    return False
                    
                if self.conn is not None:
                    with self.conn.cursor() as cursor:
                        cursor.execute(query, [record_id])
                    return True
                return False
            except Exception as e:
                self.logger.error(f"Error deleting record (attempt {retry_count+1}): {str(e)}")
                retry_count += 1
                if retry_count >= self.max_retry:
                    return False
                time.sleep(0.1)  # Sleep for 0.1 second before retrying
                
        return False

    def load_from_csv(self, table_name: str, csv_path: str, sep: str = '|', header: bool = False) -> bool:
        """
        Load a batch of records from csv.
        Should check if the table_name exists,
        then write and execute an SQL in Postgres syntax to load all records from this csv.
        Additional arguments, such as sep, header are the arguments related to CSV loading.
        You should expand the function input to include more such arguments with their default value.
        Returns:
            bool: True if successfully loaded, False otherwise.
        """
        if not self._table_exists(table_name):
            self.logger.error(f"Table {table_name} does not exist")
            return False
            
        try:
            # Get table columns
            table = self.schema.table_dictionary.get(table_name)
            if table is None:
                return False
                
            # Read CSV file
            records = []
            with open(csv_path, 'r', newline='') as csvfile:
                if header:
                    # Skip header row
                    next(csvfile)
                    
                csv_reader = csv.reader(csvfile, delimiter=sep)
                for row in csv_reader:
                    # Convert empty strings to None
                    processed_row = [None if val == '' else val for val in row]
                    records.append(processed_row)
            
            # Insert each record
            success = True
            for record in records:
                if not self.insert_record(table_name, record):
                    success = False
                    
            return success
        except Exception as e:
            self.logger.error(f"Error loading data from CSV {csv_path}: {str(e)}")
            return False

    def create_index(self, index_name: str, table_name: str, col_names: t.List[str]) -> bool:
        """
        Create an index with name index_name on table (table_name) over a list of columns (col_names).
        You should write and execute an SQL in Postgres syntax to do create index.
        Check if table_name and col_names exist.
        Remember the common case where col_names has length of 1.
        Returns:
            bool: True if successfully created, False otherwise.
        """
        if not self._table_exists(table_name):
            self.logger.error(f"Table {table_name} does not exist")
            return False
            
        # Verify columns exist in the table
        table = self.schema.table_dictionary.get(table_name)
        if table is None:
            return False
            
        for col in col_names:
            if col not in table.columns:
                self.logger.error(f"Column {col} does not exist in table {table_name}")
                return False
                
        # Construct column list for index
        column_list = ", ".join(col_names)
        
        # Construct the query
        query = f"CREATE INDEX IF NOT EXISTS {index_name} ON {table_name} ({column_list})"
        
        try:
            result = self._execute_with_retry(query)
            return result is not None
        except Exception as e:
            self.logger.error(f"Error creating index {index_name}: {str(e)}")
            return False

    def drop_index(self, index_name: str) -> bool:
        """
        Write and execute an SQL in Postgres syntax to drop an index.
        Returns:
            bool: True if successfully dropped, False otherwise.
        """
        try:
            # Check if index exists
            check_query = """
            SELECT 1 FROM pg_indexes WHERE indexname = %s
            """
            result = self._execute_with_retry(check_query, [index_name])
            
            if result and len(result) > 0:
                # Index exists, drop it
                drop_query = f"DROP INDEX {index_name}"
                result = self._execute_with_retry(drop_query)
                return result is not None
            else:
                self.logger.info(f"Index {index_name} does not exist, no need to drop")
                return True
        except Exception as e:
            self.logger.error(f"Error dropping index {index_name}: {str(e)}")
            return False
---------------------------------------------

Here is the review to this output:
---------------------------------------------
# Transpilation Review
The transpilation is not correct. There are several attribute errors related to the BaseTable class in the PostgresOperations implementation.

## Compilation Review
### Failures
The compilation errors are related to accessing attributes that don't exist in the BaseTable class:
1. `BaseTable` has no attribute `columns` (lines 386, 453, 512, 657)
2. `BaseTable` has no attribute `column_types`; maybe `column_types_list`? (line 387)
3. `BaseTable` has no attribute `foreign_keys`; maybe `foreign_key_ref`? (line 396)

### Fixes
Based on the error messages, it appears that the BaseTable class has different attribute names than what's being used in the code. The fixes would be:

1. Replace `table.columns` with the correct attribute name (possibly `table.column_names`)
2. Replace `table.column_types` with `table.column_types_list`
3. Replace `table.foreign_keys` with `table.foreign_key_ref`

We need to adjust the implementation to use the correct attribute names from the BaseTable class.

## Testing Review
No testing errors were provided.

## Dependency Analysis Review
The dependency analysis appears to be correct. The file correctly imports Schema and BaseTable from database.schema, which are needed for the implementation. The other imports (psycopg, logging, time, typing, csv) are also appropriate for the functionality being implemented.
---------------------------------------------

Give an overall rating of the output that also considers the review. The review must be one of the following three values: 'certainly correct', 'uncertain', or 'certainly wrong'

Wrap your answer into a <rating> tag, i.e.:

<rating>
'certainly correct', 'uncertain', or 'certainly wrong'
</rating>

********************

I have a high-level design doc and want to turn it into code using LLMs. I chain together several LLM calls to achieve this, were I first have a planning phase and then a transpilation phase.

Below are an outputs and review for one of the steps. Based on the output and the review, I want you to label the step's correctness as either 'certainly correct', 'uncertain', or 'certainly wrong'.

Your rating must only contain one of these three values. This is how you should assign them:

1. 'certainly correct': Based on code and review, the step produced an output that is certainly correct and will not cause any problems further down the transpilation process.

2. 'uncertain': It is hard to tell whether the output is correct or incorrect.

3. 'certainly incorrect': Based on code and review, the step produced an output that is certainly incorrect as is. The problems might be fixable in the future but the current output is erreneous, either by being too vague, underspecified or producing wrong code (e.g., code that doesn't compile).

Here is the LLM's output:
---------------------------------------------
import psycopg
import logging
import time
import typing as t
import csv
from database.schema import Schema, BaseTable


class DBOperationsInterface:
    """
    Interface for defining all database related operations to backup the CRM.
    """
    def __init__(self,
                 db_name: str,
                 schema: Schema,
                 host: str,
                 port: str,
                 user: str,
                 password: str,
                 max_retry: int = 3,
                 timeout_s: int = 200):
        """
        Feel free to add any other attributes you think may be useful
        """
        self.db_name = db_name
        self.schema = schema
        self.host = host
        self.port = port
        self.user = user
        self.password = password
        self.max_retry = max_retry
        self.timeout_s = timeout_s
        self.conn: t.Optional[psycopg.Connection] = None

    def get_connection(self) -> bool:
        """
        Using psycopg package to create a database connection to database named self.db_name.
        """
        raise NotImplementedError('Inherit me!')

    def close_connection(self) -> bool:
        """
        close the psycopg connection in self.conn and set it to None
        """
        raise NotImplementedError('Inherit me!')

    def create_database_schema(self) -> bool:
        """
        Execute SQL query to load the database schema.
        """
        raise NotImplementedError('Inherit me!')

    def execute_query(self, query: str):
        """
        Execute the SQL query provided and return the results.
        """
        raise NotImplementedError('Inherit me!')

    def create_table(self, table_name: str) -> bool:
        """
        Execute this SQL query to create table. Do not do anything if the table exists.
        """
        raise NotImplementedError('Inherit me!')

    def drop_table(self, table_name: str) -> bool:
        """
        Execute this SQL query to drop an existing table.
        """
        raise NotImplementedError('Inherit me!')

    def insert_record(self, table_name: str, record: t.List[t.Any]) -> bool:
        """
        Insert one record into table.
        """
        raise NotImplementedError('Inherit me!')

    def update_record(self, table_name: str, record: t.List[t.Any]) -> bool:
        """
        Update one record in the table.
        """
        raise NotImplementedError('Inherit me!')

    def delete_record(self, table_name: str, record_id: int) -> bool:
        """
        Delete record with record_id in the table.
        """
        raise NotImplementedError('Inherit me!')

    def load_from_csv(self, table_name: str, csv_path: str, sep: str = '|', header: bool = False) -> bool:
        """
        Load a batch of records from csv.
        """
        raise NotImplementedError('Inherit me!')

    def create_index(self, index_name: str, table_name: str, col_names: t.List[str]) -> bool:
        """
        Create an index with name index_name on table (table_name) over a list of columns (col_names).
        """
        raise NotImplementedError('Inherit me!')

    def drop_index(self, index_name: str) -> bool:
        """
        Write and execute an SQL in Postgres syntax to drop an index.
        """
        raise NotImplementedError('Inherit me!')


class PostgresOperations(DBOperationsInterface):
    """
    Interface for defining all database related operations to backup the CRM.
    """

    def __init__(self,
                 db_name: str,
                 schema: Schema,
                 host: str,
                 port: str,
                 user: str,
                 password: str,
                 max_retry: int = 3,
                 timeout_s: int = 200):
        """
        Initialize PostgreSQL operations with connection parameters
        """
        super().__init__(db_name, schema, host, port, user, password, max_retry, timeout_s)
        self.logger = logging.getLogger(__name__)

    def get_connection(self) -> bool:
        """
        Using psycopg package to create a database connection to database named self.db_name.
        If self.db_name does not exist, you should first connect to admin database with name 'postgres',
        create a database with name self.db_name, and then connect to self.db_name.
        Set it as self.conn
        Hint: You can set conn.autocommit = True to avoid commit transaction every time
         after setting the connection, you should set the timeout in seconds as self._timeout_s,
        Returns:
            bool: True if successfully connected, False otherwise.
        """
        try:
            # Try to connect to the specified database
            conn = psycopg.connect(
                host=self.host,
                port=self.port,
                dbname=self.db_name,
                user=self.user,
                password=self.password,
                connect_timeout=self.timeout_s
            )
            conn.autocommit = True
            self.conn = conn
            return True
        except psycopg.errors.OperationalError as e:
            # If database doesn't exist, connect to postgres and create it
            if "database" in str(e) and "does not exist" in str(e):
                try:
                    # Connect to postgres database
                    admin_conn = psycopg.connect(
                        host=self.host,
                        port=self.port,
                        dbname="postgres",
                        user=self.user,
                        password=self.password,
                        connect_timeout=self.timeout_s
                    )
                    admin_conn.autocommit = True
                    
                    # Create the database
                    with admin_conn.cursor() as cursor:
                        cursor.execute(f"CREATE DATABASE {self.db_name}")
                    
                    admin_conn.close()
                    
                    # Now connect to the newly created database
                    conn = psycopg.connect(
                        host=self.host,
                        port=self.port,
                        dbname=self.db_name,
                        user=self.user,
                        password=self.password,
                        connect_timeout=self.timeout_s
                    )
                    conn.autocommit = True
                    self.conn = conn
                    return True
                except Exception as create_ex:
                    self.logger.error(f"Failed to create database: {str(create_ex)}")
                    return False
            else:
                self.logger.error(f"Failed to connect to database: {str(e)}")
                return False
        except Exception as e:
            self.logger.error(f"Unexpected error connecting to database: {str(e)}")
            return False

    def close_connection(self) -> bool:
        """
        close the psycopg connection in self.conn and set it to None
        Returns:
            bool: True if successfully closed connection, False otherwise.
        """
        try:
            if self.conn is not None:
                self.conn.close()
                self.conn = None
            return True
        except Exception as e:
            self.logger.error(f"Error closing connection: {str(e)}")
            return False

    def create_database_schema(self) -> bool:
        """
        Execute SQL query (self.schema.schema_sql_statement) to create the database schema.
        Returns:
            bool: True if successfully created schema, False otherwise.
        """
        if self.conn is None and not self.get_connection():
            return False
            
        try:
            # Execute the schema SQL statement
            if self.conn is not None:
                with self.conn.cursor() as cursor:
                    cursor.execute(self.schema.schema_sql_statement)
                return True
            return False
        except Exception as e:
            self.logger.error(f"Error creating database schema: {str(e)}")
            return False

    def drop_database(self) -> bool:
        """
        Drop self.db_name database,
        You should create a connection to admin database with name 'postgres', then write SQL in Postgres-syntax to
        drop this database.
        Close connection
        Returns:
            bool: True if successfully dropped, False otherwise.
        """
        try:
            # Close current connection if exists
            if self.conn is not None:
                self.conn.close()
                self.conn = None
                
            # Connect to postgres database
            admin_conn = psycopg.connect(
                host=self.host,
                port=self.port,
                dbname="postgres",
                user=self.user,
                password=self.password,
                connect_timeout=self.timeout_s
            )
            admin_conn.autocommit = True
            
            # Terminate all connections to the database
            with admin_conn.cursor() as cursor:
                cursor.execute(f"""
                    SELECT pg_terminate_backend(pg_stat_activity.pid)
                    FROM pg_stat_activity
                    WHERE pg_stat_activity.datname = '{self.db_name}'
                    AND pid <> pg_backend_pid()
                """)
                
                # Drop the database
                cursor.execute(f"DROP DATABASE IF EXISTS {self.db_name}")
                
            admin_conn.close()
            return True
        except Exception as e:
            self.logger.error(f"Error dropping database: {str(e)}")
            return False

    def _execute_with_retry(self, query: str, params: t.Optional[t.List[t.Any]] = None) -> t.Optional[t.List[t.Any]]:
        """
        Helper method to execute a query with retry logic.
        
        Args:
            query: SQL query to execute
            params: Parameters for the query
            
        Returns:
            Query results or None if execution failed
        """
        retry_count = 0
        while retry_count < self.max_retry:
            try:
                if self.conn is None and not self.get_connection():
                    self.logger.error("Failed to get connection")
                    return None
                    
                if self.conn is not None:
                    with self.conn.cursor() as cursor:
                        if params:
                            cursor.execute(query, params)
                        else:
                            cursor.execute(query)
                        
                        try:
                            results = cursor.fetchall()
                            return results
                        except psycopg.ProgrammingError:
                            # No results to fetch (e.g., for INSERT, UPDATE, DELETE)
                            return []
                return None
            except Exception as e:
                self.logger.error(f"Error executing query (attempt {retry_count+1}): {str(e)}")
                retry_count += 1
                if retry_count >= self.max_retry:
                    return None
                time.sleep(1)  # Sleep for 1 second before retrying
        
        return None

    def execute_query(self, query: str) -> t.Any:
        """
        Execute the SQL query provided and return the results.
        If execution not successful, you should sleep for 1s and try again. There are at most self.max_retry number of retrys.
        Hint: you should get connection if connection is closed. Use self._execute_with_retry helper function
        Returns:
            results: return the results of this query, None if execution not successful.
        """
        return self._execute_with_retry(query)

    def _table_exists(self, table_name: str) -> bool:
        """
        Check if a table exists in the database.
        
        Args:
            table_name: Name of the table to check
            
        Returns:
            True if the table exists, False otherwise
        """
        query = """
        SELECT 1 FROM information_schema.tables 
        WHERE table_schema = 'public' AND table_name = %s
        """
        result = self._execute_with_retry(query, [table_name])
        return result is not None and len(result) > 0

    def _record_exists(self, table_name: str, record_id: int) -> bool:
        """
        Check if a record exists in a table.
        
        Args:
            table_name: Name of the table to check
            record_id: ID of the record to check
            
        Returns:
            True if the record exists, False otherwise
        """
        # Get the primary key column name
        table = self.schema.table_dictionary.get(table_name)
        if table is None:
            return False
            
        primary_key = table.primary_key[0]
        
        query = f"SELECT 1 FROM {table_name} WHERE {primary_key} = %s"
        result = self._execute_with_retry(query, [record_id])
        return result is not None and len(result) > 0

    def create_table(self, table_name: str) -> bool:
        """
        Execute the SQL query to create table. Do not do anything if the table exists.
        The create table sql statement can be found in self.schema.table_dictionary[table_name]
        Returns:
            bool: True if successfully created table, False otherwise.
        """
        if self._table_exists(table_name):
            self.logger.info(f"Table {table_name} already exists")
            return True
            
        try:
            table = self.schema.table_dictionary.get(table_name)
            if not table:
                self.logger.error(f"Table {table_name} not found in schema")
                return False
                
            # Assuming BaseTable has a method to get SQL or we can construct it from table attributes
            create_table_sql = f"CREATE TABLE {table_name} ("
            
            # Add columns
            column_defs = []
            for i, col_name in enumerate(table.column_names):
                col_type = table.column_types_list[i]
                column_defs.append(f"{col_name} {col_type}")
                
            # Add primary key
            if table.primary_key:
                pk_cols = ", ".join(table.primary_key)
                column_defs.append(f"PRIMARY KEY ({pk_cols})")
                
            # Add foreign keys
            for fk in table.foreign_key_ref:
                ref_table = fk.reference_table
                ref_cols = ", ".join(fk.reference_columns)
                cols = ", ".join(fk.columns)
                column_defs.append(f"FOREIGN KEY ({cols}) REFERENCES {ref_table}({ref_cols})")
                
            create_table_sql += ", ".join(column_defs) + ")"
            
            result = self._execute_with_retry(create_table_sql)
            return result is not None
        except Exception as e:
            self.logger.error(f"Error creating table {table_name}: {str(e)}")
            return False

    def drop_table(self, table_name: str) -> bool:
        """
        Execute this SQL query to drop a table if exists.
        Returns:
            bool: True if successfully dropped schema, False otherwise.
        """
        try:
            query = f"DROP TABLE IF EXISTS {table_name}"
            result = self._execute_with_retry(query)
            return result is not None
        except Exception as e:
            self.logger.error(f"Error dropping table {table_name}: {str(e)}")
            return False

    def insert_record(self, table_name: str, record: t.List[t.Any]) -> bool:
        """
        Insert one record into table.
        Should check if the table_name exists (raise appropriate error otherwise),
        Then write and execute an SQL in Postgres syntax to insert this record.
        Note that your SQL statement should check if record id (record[0]) already exists, insert this tuple if it does not exist.
        If this tuple already exist, call self.update_record(table_name, record) instead.
        If execution not successful, you should sleep for 0.1s and try again. There are at most self.max_retry number of retrys.
        Returns:
            bool: True if successfully inserted record, False otherwise.
        """
        if not self._table_exists(table_name):
            self.logger.error(f"Table {table_name} does not exist")
            return False
            
        # Get table information
        table = self.schema.table_dictionary.get(table_name)
        if table is None:
            return False
            
        primary_key = table.primary_key[0]
        
        # Check if record with this ID already exists
        record_id = record[0]
        if self._record_exists(table_name, record_id):
            # Record exists, update it instead
            return self.update_record(table_name, record)
            
        # Prepare column names and placeholders
        column_names = ", ".join(table.column_names)
        placeholders = ", ".join(["%s" for _ in range(len(record))])
        
        # Construct the query
        query = f"INSERT INTO {table_name} ({column_names}) VALUES ({placeholders})"
        
        # Execute with retry
        retry_count = 0
        while retry_count < self.max_retry:
            try:
                if self.conn is None and not self.get_connection():
                    return False
                    
                if self.conn is not None:
                    with self.conn.cursor() as cursor:
                        cursor.execute(query, record)
                    return True
                return False
            except Exception as e:
                self.logger.error(f"Error inserting record (attempt {retry_count+1}): {str(e)}")
                retry_count += 1
                if retry_count >= self.max_retry:
                    return False
                time.sleep(0.1)  # Sleep for 0.1 second before retrying
                
        return False

    def update_record(self, table_name: str, record: t.List[t.Any]) -> bool:
        """
        Update one record in the table.
        The id of the record is defined as the first element in record, i.e., record[0]
        You should first check if this id appears in the table in the database.
        If not, call insert_record() and return.
        Then write and execute an SQL in Postgres syntax to update this record with the id.
        In the case where record id is not found in the table, insert this record using insert_record().
        If execution not successful, you should sleep for 0.1s and try again. There are at most self.max_retry number of retrys.
        Note: the column name for id attributes as self.schema.table_dictionary[table_name].primary_key[0]
        Returns:
            bool: True if successfully updated record, False otherwise.
        """
        if not self._table_exists(table_name):
            self.logger.error(f"Table {table_name} does not exist")
            return False
            
        # Get table information
        table = self.schema.table_dictionary.get(table_name)
        if table is None:
            return False
            
        primary_key = table.primary_key[0]
        
        # Check if record with this ID exists
        record_id = record[0]
        if not self._record_exists(table_name, record_id):
            # Record doesn't exist, insert it instead
            return self.insert_record(table_name, record)
            
        # Prepare SET clause
        set_clauses = []
        for i, col in enumerate(table.column_names):
            if i > 0:  # Skip the primary key (first column)
                set_clauses.append(f"{col} = %s")
                
        set_clause = ", ".join(set_clauses)
        
        # Construct the query
        query = f"UPDATE {table_name} SET {set_clause} WHERE {primary_key} = %s"
        
        # Prepare parameters: all values except primary key, followed by primary key for WHERE clause
        params = record[1:] + [record[0]]
        
        # Execute with retry
        retry_count = 0
        while retry_count < self.max_retry:
            try:
                if self.conn is None and not self.get_connection():
                    return False
                    
                if self.conn is not None:
                    with self.conn.cursor() as cursor:
                        cursor.execute(query, params)
                    return True
                return False
            except Exception as e:
                self.logger.error(f"Error updating record (attempt {retry_count+1}): {str(e)}")
                retry_count += 1
                if retry_count >= self.max_retry:
                    return False
                time.sleep(0.1)  # Sleep for 0.1 second before retrying
                
        return False

    def delete_record(self, table_name: str, record_id: int) -> bool:
        """
        Delete record with record_id in the table.
        Then write and execute an SQL in Postgres syntax to delete this record with the id.
        Note: the column name for id attributes as self.schema.table_dictionary[table_name].primary_key[0]
        If execution not successful, you should sleep for 0.1s and try again. There are at most self.max_retry number of retrys.
        Returns:
            bool: True if successfully deleted record, False otherwise.
        """
        if not self._table_exists(table_name):
            self.logger.error(f"Table {table_name} does not exist")
            return False
            
        # Get primary key column name
        table = self.schema.table_dictionary.get(table_name)
        if table is None:
            return False
            
        primary_key = table.primary_key[0]
        
        # Check if record exists
        if not self._record_exists(table_name, record_id):
            self.logger.info(f"Record with ID {record_id} does not exist in table {table_name}")
            return True  # Consider it a success if the record doesn't exist
            
        # Construct the query
        query = f"DELETE FROM {table_name} WHERE {primary_key} = %s"
        
        # Execute with retry
        retry_count = 0
        while retry_count < self.max_retry:
            try:
                if self.conn is None and not self.get_connection():
                    return False
                    
                if self.conn is not None:
                    with self.conn.cursor() as cursor:
                        cursor.execute(query, [record_id])
                    return True
                return False
            except Exception as e:
                self.logger.error(f"Error deleting record (attempt {retry_count+1}): {str(e)}")
                retry_count += 1
                if retry_count >= self.max_retry:
                    return False
                time.sleep(0.1)  # Sleep for 0.1 second before retrying
                
        return False

    def load_from_csv(self, table_name: str, csv_path: str, sep: str = '|', header: bool = False) -> bool:
        """
        Load a batch of records from csv.
        Should check if the table_name exists,
        then write and execute an SQL in Postgres syntax to load all records from this csv.
        Additional arguments, such as sep, header are the arguments related to CSV loading.
        You should expand the function input to include more such arguments with their default value.
        Returns:
            bool: True if successfully loaded, False otherwise.
        """
        if not self._table_exists(table_name):
            self.logger.error(f"Table {table_name} does not exist")
            return False
            
        try:
            # Get table columns
            table = self.schema.table_dictionary.get(table_name)
            if table is None:
                return False
                
            # Read CSV file
            records = []
            with open(csv_path, 'r', newline='') as csvfile:
                if header:
                    # Skip header row
                    next(csvfile)
                    
                csv_reader = csv.reader(csvfile, delimiter=sep)
                for row in csv_reader:
                    # Convert empty strings to None
                    processed_row = [None if val == '' else val for val in row]
                    records.append(processed_row)
            
            # Insert each record
            success = True
            for record in records:
                if not self.insert_record(table_name, record):
                    success = False
                    
            return success
        except Exception as e:
            self.logger.error(f"Error loading data from CSV {csv_path}: {str(e)}")
            return False

    def create_index(self, index_name: str, table_name: str, col_names: t.List[str]) -> bool:
        """
        Create an index with name index_name on table (table_name) over a list of columns (col_names).
        You should write and execute an SQL in Postgres syntax to do create index.
        Check if table_name and col_names exist.
        Remember the common case where col_names has length of 1.
        Returns:
            bool: True if successfully created, False otherwise.
        """
        if not self._table_exists(table_name):
            self.logger.error(f"Table {table_name} does not exist")
            return False
            
        # Verify columns exist in the table
        table = self.schema.table_dictionary.get(table_name)
        if table is None:
            return False
            
        for col in col_names:
            if col not in table.column_names:
                self.logger.error(f"Column {col} does not exist in table {table_name}")
                return False
                
        # Construct column list for index
        column_list = ", ".join(col_names)
        
        # Construct the query
        query = f"CREATE INDEX IF NOT EXISTS {index_name} ON {table_name} ({column_list})"
        
        try:
            result = self._execute_with_retry(query)
            return result is not None
        except Exception as e:
            self.logger.error(f"Error creating index {index_name}: {str(e)}")
            return False

    def drop_index(self, index_name: str) -> bool:
        """
        Write and execute an SQL in Postgres syntax to drop an index.
        Returns:
            bool: True if successfully dropped, False otherwise.
        """
        try:
            # Check if index exists
            check_query = """
            SELECT 1 FROM pg_indexes WHERE indexname = %s
            """
            result = self._execute_with_retry(check_query, [index_name])
            
            if result and len(result) > 0:
                # Index exists, drop it
                drop_query = f"DROP INDEX {index_name}"
                result = self._execute_with_retry(drop_query)
                return result is not None
            else:
                self.logger.info(f"Index {index_name} does not exist, no need to drop")
                return True
        except Exception as e:
            self.logger.error(f"Error dropping index {index_name}: {str(e)}")
            return False
---------------------------------------------

Here is the review to this output:
---------------------------------------------
# Transpilation Review
The transpilation is not correct. There are several type errors in the code that need to be fixed.

## Compilation Review
### Failures
1. Type annotation errors for variables in loops
2. Accessing methods on column_names which is a callable function instead of a list
3. Accessing attributes on strings in the foreign key handling
4. Using callable functions instead of their return values in several places

### Fixes
1. Fix the `create_table` method to properly access table attributes:
   - Change `for i, col_name in enumerate(table.column_names):` to `for i, col_name in enumerate(table.column_names()):`
   - Add type annotation for col_name: `for i, col_name: str in enumerate(table.column_names()):`
   - Fix foreign key handling to properly access the foreign key reference objects

2. Fix the `insert_record` method:
   - Change `column_names = ", ".join(table.column_names)` to `column_names = ", ".join(table.column_names())`

3. Fix the `update_record` method:
   - Add type annotation for col: `for i, col: str in enumerate(table.column_names()):`
   - Change `table.column_names` to `table.column_names()`

4. Fix the `create_index` method:
   - Change `if col not in table.column_names:` to `if col not in table.column_names():`

## Testing Review
No testing errors were provided.

## Failures due to other causes
None identified. All errors appear to be in this file.

## Dependency Analysis Review
The dependency analysis seems correct. The file depends on:
- psycopg for PostgreSQL database operations
- logging for error logging
- time for retry delays
- typing for type annotations
- csv for CSV file operations
- database.schema for Schema and BaseTable classes

These dependencies are all relevant and necessary for the implementation.
---------------------------------------------

Give an overall rating of the output that also considers the review. The review must be one of the following three values: 'certainly correct', 'uncertain', or 'certainly wrong'

Wrap your answer into a <rating> tag, i.e.:

<rating>
'certainly correct', 'uncertain', or 'certainly wrong'
</rating>