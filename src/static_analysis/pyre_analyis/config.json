{
  "version": "1.0.0",
  "analysis": {
    "timeout": 120,
    "max_workers": "auto",
    "sequential": false,
    "fast_mode": true,
    "use_cache": true,
    "incremental": true,
    "daemon_mode": true,
    "watch_filesystem": true,
    "persistent_cache": true
  },
  "llm_patterns": {
    "openai": [
      "openai.chat.completions.create",
      "openai.Completion.create", 
      "openai.completions.create",
      "openai.responses.create",
      "client.chat.completions.create",
      "client.completions.create",
      "client.responses.create"
    ],
    "anthropic": [
      "anthropic.messages.create",
      "client.messages.create"
    ],
    "generic": [
      "call_llm",
      "llm_call",
      "ai_call"
    ]
  },
  "taint_config": {
    "sources": [
      {
        "name": "LLMOutput",
        "comment": "Output from LLM API calls"
      }
    ],
    "sinks": [
      {
        "name": "LLMInput",
        "comment": "Input to LLM API calls"
      }
    ],
    "rules": [
      {
        "name": "LLM data flow",
        "code": 5001,
        "sources": ["LLMOutput"],
        "sinks": ["LLMInput"],
        "message_format": "Data from {$sources} may reach {$sinks}"
      }
    ]
  },
  "ast_transforms": {
    "enabled": true,
    "simplify_member_variables": true,
    "simplify_dictionary_operations": true,
    "simplify_function_chains": true,
    "preserve_line_numbers": true
  },
  "output": {
    "format": "json",
    "include_source_sink_details": true,
    "include_line_column": true,
    "save_to_file": true,
    "filename": "results/pyre_analysis_results.json"
  },
  "daemon": {
    "auto_start": true,
    "auto_restart_on_config_change": true,
    "cleanup_on_exit": true,
    "max_idle_time": 3600,
    "enable_file_watching": true
  }
} 